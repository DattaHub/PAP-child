---
title: "Little Rock Child Maltreatment: <br>  Predictive Analysis"
author: "UA Research Team"
date: "October 3, 2019"
output: 
  html_document:
      toc: true
      number_sections: true
      toc_float: true 
      toc_depth: 6
      theme: united
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(comment = NA,
               echo = FALSE,
               prompt = FALSE,
               cache = FALSE,
               warning = FALSE,
               message = FALSE)
```


```{r packages, message=FALSE, warning=FALSE, cache=F}
if(T){
  library("sf")            # Spatial data objects and methods
  library("mapview")       # Interactive Map Viewing
  library("ggmap")         # ggplot2 addon for base maps
  library("cowplot")
  library("spatstat")      # KDE and other spatial functions
  library("raster")        # cell-based spatial operations
  library("tidyverse")     # data manipulation framework
  library("Hmisc")         # using cut2() functions for ggplot legends
  library("fitdistrplus")  # Distribution fitting functions
  library("lubridate")     # Power tools for handling dates
  library("tidycensus")
  library("lwgeom")
  library("Hmisc")
  library("hrbrthemes")
  library("gridExtra")
  library("patchwork")
  library("spdep")         # KNN functions
  library("foreach")
  library("doParallel")
  library("corrplot")
  library("ranger")        # randomforest implimentation      
  library("glmnet")        # for Ridge and Lasso Regression
  library("knitr")         # for kable table
  library("kableExtra")
  library("FNN")           # KNN for CPS vs. NN plots
  library("groupdata2")
  library("htmltools")
  library("viridis")
  library("viridisLite")
  library(sjPlot)
  library(sjlabelled)
  library(sjmisc)
}
```


```{r themes}
mapTheme <- function() {
  theme(
    plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
    plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
    plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.ticks = element_blank(),
    axis.line = element_blank(),
    legend.title = element_text(size = 10, family = "sans"),
    legend.text = element_text(size = 9, family = "sans"),
    panel.border = element_blank()
  )
}

plotTheme <- function() {
  theme(
    plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
    plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
    plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0), 
    axis.title.x = element_text(size = 10, family = "sans", face = "plain", hjust = 1, vjust = -0.5),
    axis.title.y = element_text(size = 10, family = "sans", face = "plain", hjust = 1, vjust = 1),
    axis.text = element_text(size = 7, family = "sans", face = "plain"),
    panel.background = element_blank(),
    panel.grid.minor = element_line(colour = "gray"),
    panel.grid.major = element_line(colour = "gray"),
    axis.ticks = element_blank(),
    legend.title = element_text(size = 10, family = "sans"),
    legend.text = element_text(size = 9, family = "sans"),
    axis.line = element_blank()
  )
}
```

```{r options}
if(T){
  mapviewOptions(basemaps = c("Stamen.TonerLite", "OpenStreetMap.DE"))
  base_dir = "C:/Users/jd033/Box/LR-Project"
  fishnet_grid_dim = 1000
  k_direction = 8 # 4 = rook, 8 = queen
  k_nearest_neighbors = 5
  # Either k (e.g. 5 or 10) or "LOOCV"
  n_folds = 10
  # threshold quntile for statArea grouping
  stat_area_quantile = 0.60
  # Number of simulations for CPS vs. NN
  simulations = 1000
  # Number of neighbors for CPS vs. NN
  k = 5
  # random seed
  set.seed(11235)
}
```

```{r SOURCE, cache = T}
## Source 

source('C:/Users/jd033/Box/Child Maltreatment/R-codes/FUNCTIONS_VAPAP_LR.R', echo = FALSE, keep.source = TRUE)
source('C:/Users/jd033/Box/Child Maltreatment/R-codes/FEA_CREATE_VARIABLES_LR_2.R', echo = FALSE, keep.source = TRUE)

## Can be also loaded via 
# load("Rdata/source_file_objects.RData")
```

```{R load_all_results, echo = F}
# load("full_results_line_2102_0807.RData")
load("full_results_line_2642_0827.RData")
```

# Predict Phase

**Note: The analytical framework, that is, modeling, diagnostics, prediction as well as the narrative in the following report are replicated from the (https://urbanspatial.github.io/PredictingChildMaltreatmentInRichmondVA/). We will rewrite the report if need be.**

## Motivation 

Figure 1.1a shows the count of maltreatment events between 2015 and 2018 by census tracts and it shows that not all areas are affected by maltreatment in the same manner. A key question is how do we ensure that our limited child welfare resources are properly deployed to the communities where they are needed most?
  
  To understand which communities have the greatest need, we must first determine where child maltreatment is likely to occur. While there are a host of individual, family, and household level factors associated with child maltreatment, research shows that community and social factors play an important role in understanding where maltreatment may occur.[^2] At high densities, externalities associated with these 'neighborhood effects' can influence peers in close proximity.[^3] 

These spillover effects appear as maltreatment event clusters, as visualized in Figure 1.1b, which maps the rate of child maltreatment events in Little Rock, AR between 2015 and 2018.[^4] Recent work shows that variation in these spatial clusters can be predicted by environmental factors such as crime, blight, and nuisance land uses like bars and restaurants.[^5]

```{r cache = TRUE,echo=FALSE, warning=FALSE, include = TRUE, fig.width=11.5, fig.height=5}
cowplot::plot_grid(CPSCOUNT_by_lr_tract_plot, CPS_RATE_BY_FISHNET_PLOT, align = "hv", axis = "lrbt")
```


## Exploratory Analysis
  
In this section, we derive a number of descriptive insights from our data. To begin, maltreatment events across space and time are visualized and we discuss some of the possible selection bias in the data. Next, hypotheses related to the clustering of maltreatment events across space are presented. Finally, we calculate a series of pairwise correlations between maltreatment and our features.
  
### Analysis of maltreatment events over time and space
  
  Figure below plots the counts of child maltreatment events throughout the study period which began midway from 2015 and ended midway through 2018. As we do not observe these reporting changes, time variation cannot be used for model validation. 
  
```{r countEventsFishnet2, warning=FALSE, message = FALSE, cache = TRUE, echo=FALSE, include = TRUE, fig.align = "center", fig.width=8}

(CPS_HIST_BY_DATE | CPS_LINE_AGG_BY_MOTNH_plot) / (CPS_LINE_NORMALIZED_plot | CPS_TREND_BY_MONTH_YEAR_plot)


CPS_POINT_BY_MONTH_plot

CPS_CALENDAR_plot

```

<!-- Although the counts may vary over time, they appear to be relatively consistent across space. Figure 5.2 shows the density of maltreatment events across space between 2015 and 2018. This is a strong indicator that the aforementioned reporting bias has less of an effect across space. -->

<!-- ```{r warning=FALSE, message = FALSE, cache = TRUE, echo=FALSE, include = TRUE, fig.align = "center", fig.width = 10} -->
<!-- CPS_KDE_BY_YEAR_plot -->
<!-- ``` -->
  
<!-- ###Visualizing risk and protective features -->
  
<!-- Figures 5.3 and 5.4 plot the spatial density of selected protective and risk factors, respectively. -->

<!-- ```{r warning=FALSE, message = FALSE, cache = TRUE, echo=FALSE, include = TRUE, fig.align = "center", fig.width=12, fig.height=12} -->
<!-- PROTECTIVE_KDE_FACET_PLOT -->
<!-- ``` -->


<!-- ```{r warning=FALSE, message = FALSE, cache = TRUE, echo=FALSE, include = TRUE, fig.align = "center", fig.width=12, fig.height=12} -->
<!-- RISK_KDE_FACET_PLOT -->
<!-- ``` -->
  
  
### Testing maltreatment events for clusters
  
One overarching assumption behind our model is that maltreatment events are clustered in space. To test this hypothesis, the Local Moran's I statistic is employed. 
 
The Local Moran's I statistic asks if the local distribution in the rate of maltreatment events, defined by a spatial weights matrix, is more clustered than we would expect due to random chance alone. The next figure plots the Local Moran's I results. The first panel shows the count of maltreatment events; Panel 2 shows the Local Moran's I value; and Panel 3 shows areas that exhibit statistically significant clustering. Panel 3 shows areas that resemble discrete clusters of maltreatment in space.
  
```{r moranIExp, cache = TRUE, warning=FALSE,echo=FALSE, include = TRUE,include = TRUE, fig.height=10}
  MORANS_I_P_plot
```

## Feature Engineering 

### Pairwise correlations
  
  In the Feature Engineering phase, we create many features from the available data on crime, built environment factors and census data. The two figures below visualize pairwise correlations for the most correlative risk and protective factors respectively. Note the correlation coefficients associated with maltreatment count (`cps_net`) and maltreatment rate (`cps_rate`). The colors of the plot vary with the strength of the correlations, either positive or negative.
  
  There are 3 different prefixes associated which each type of feature. `NN` refers to features calculated by taking the average distance between a fishnet grid cell and its $n$ nearest risk/protective factor neighbor. `ed` refers to the Euclidean distance between a fishnet grid cell and its 1 nearest risk/protective factor neighbor. `agg` refers to the count of risk/protective factor events in a given fishnet grid cell.

```{r corrplotStrongRisk,  cache = T, warning=FALSE,echo=FALSE,fig.height=15,fig.width=12, include = TRUE}
  #features_risk_strong_plot <- features_risk_strong %>%
  # dplyr::select(-net_id)

  risk_cp <- feature_corrplot(features_risk_strong_plot, "Correlation of risk features")
  #CORR_RISK_FEATURES_plot
```
  
  
```{r corrplotStrongProtective, cache = T, warning=FALSE, echo=FALSE, include = TRUE, fig.height=5, fig.align='right'}
  #features_protective_strong_plot <- features_protective_strong %>%
  #dplyr::select(-net_id)
  protective_cp <- feature_corrplot(features_protective_strong_plot, "Correlation of protective features")
  #CORR_PROTECTIVE_FEATURES_plot
```

## Model Fitting

### Model fitting & stacking

Model 'fitting' describes the process by which a statistical algorithm learns about maltreatment risk by relating the interaction of risk/protective factors to maltreatment events across space. Once a model is fit and validated, the learned pattern is applied back to the contributing features in each fishnet cell to predict the count of maltreatment events across space. This prediction highlights areas where maltreatment is present but unreported.

The first step in the model building process is to select the top few most statistically important risk and protective feature sets. We select across the different feature types (Euclidean distance, average nearest neighbor distance, and aggregate counts) based upon statistical correlation. These features make up the final feature sets, which are then subjected to our models.

Three different algorithms are fit modelling different aspects of the spatial process and then combined into a fourth 'meta-model'. The three individual models are a Poisson Generalized Linear Model (Poisson GLM), a Random Forest model, and a Spatial Durbin Model (SDM). The final prediction of maltreatment events is produced from the meta-model which is created by applying the Random Forest algorithm to the predictions made by the sub-models. The use of three different model algorithms is an effort to understand different aspects of the highly complex system that contributes to the observation of a maltreatment event. 

At each stage in this process, models are fit using a 'k-fold cross validation' routine (kFCV). kFCV splits the data into spatially explicit groups, in this case tracts, fits the models to all but $1/k$-th of the groups, and predicts maltreatment event counts for the left out folds of groups. This process, explained in greater detail below, tests how well the models generalize across neighborhoods. Below we explain the three sub-models and their inclusion in the final meta-model as well.


```{r cache = TRUE,echo=FALSE,warning=FALSE, message = FALSE, include = TRUE, fig.height = 2.5, fig.align = 'center'}
ggplot() +
  geom_sf(data=ll(net_hood), aes(fill=NAME), inherit.aes = FALSE, color = NA, alpha = 0.8) +
  scale_fill_viridis_d() +
  guides(fill=FALSE) +
  labs(title="10-fold CV",
       caption = "Figure: ") +
  mapTheme()
```

_Poisson GLM_

The Poisson GLM model, fit with the base R `glm` function, is an adaptation of linear regression that accounts for the characteristics of count data. The adaptations include modeling the residuals as Poisson distributed and transforming the linear model with a natural log function. As a result, the predictions from a Poisson model are positive and represent mean expected counts conditional on the contributing risk or protective features for each fishnet grid cell. In the meta-model, Poisson GLM predictions represent a linear model of a Poisson distributed count process. 

**Note: The Poisson GLM model is not an optimal choice as we have a modertaely high-dimensional feature space, so it runs into problems of rank-deficiency and multicollinearity. In simple words, rank deficiency happens when the design matrix has less than full rank, leading to lack of unique solutions for the GLM, and multicollinearity implies columns of $X$ matrix exhibiting high-degree of correlation, leading to inflated variance of the parameter estimates and instability. One fix is using a penalized regression that puts a budget on the parameter vector in the GLM framework, such as LASSO or Elastic Net, that cures these issues to some extent.**

_Random Forest_

In this study, the Random Forest algorithm is fit using the `ranger` library. The Random Forest algorithm builds a series of decision tree models to learn the relationship between maltreatment and exposure variables. The stochastic approach to sampling from observed data ensures that each individual tree is different from the next. The Random Forest provides a 'wisdom of many' approach, contributing non-linear interactions between maltreatment and the corresponding features to the final meta-model.


_Spatial Durbin Model_

To model spatial interrelationships - also referred to as 'spatial autocorrelation' - a Spatial Durbin Model (SDM) is fit using the `errorsarlm` function of the `spdep` package in R. In the setting of this study, the interpretation of this model is that the rate of maltreatment events is affected by both the exogenous exposure factors  as well as neighboring rates of maltreatment. Further, this model assumes that there may be latent features that impact the model errors but are not accounted by the exposure features. The key model input of spatial autocorrelation is a spatial weights matrix relating maltreatment in a given grid cell to its neighbors. Modeling the underlying spatial maltreatment process provides a powerful predictive story when input into the final meta-model. It is important to note that the SDM is not fit with the 10FCV method due to the complications of subsetting a spatial weights matrix in a cross-validation setting.

_Meta-Model_

The final maltreatment count predictions are generated from a meta-model which combines predictions from the three sub-models. The process to combine the three models is straightforward; as the predicted counts from each sub-model are used as input features of a new model fit with the Random Forest algorithm. Often referred to as model 'stacking', this technique seeks to average out the variance in the three separate models. To reduce the risk of over-fitting, the stacked meta-model is fit and predicted using the same 10FCV routine as the sub-models.

### Model validation

Assessing the accuracy and spatial generalizability of model predictions is crucial when considering how to embed this model in the provision of child welfare services. A variety of approaches are used for model validation including k-fold cross validation (kFCV) and assorted goodness of fit metrics. Some of these metrics are statistical in nature, while others measure goodness of fit across space.  

<!-- _Leave One Group Out Cross Validation_ -->

<!-- 10FCV is a technique for assuring that model predictions are generalizable across neighborhoods. The first step in 10FCV is to assign each fishnet cell to the neighborhood that encompasses it. From a policy perspective, 10FCV evaluates whether the maltreatment experience as we've modelled it is relevant to varying neighborhood contexts in Richmond. From a modeling perspective, this approach helps ensure our models are not overfit. Each of the 148 neighborhoods takes a turn as the hold out, totaling in 297 individual sub-models and 297 separate estimates of goodness of fit.[^23] -->
  
_Goodness of fit metrics_
  
  Model error is defined simply as the difference between the observed count of maltreatment events and the predicted count for each grid cell. Complicating matters is that 297 models yields more than 567,000 grid cell level predictions. We derive several statistics to summarize and aggregate these errors in order to judge models and compare across them. We describe each below:
    
The Mean Absolute Error or MAE, measures the average absolute difference between the observed and predicted values. An example interpretation of MAE is that, 'on average, the model is off by plus or minus 1.67 events'. MAE is simple to interpret in a policy context, however, it comes with some drawbacks, namely that the direction of the error is unknown and that every error is assumed to have the same severity. The MAE assumes that an error between a predicted count of 5 and an observed count of 7 events should be considered the same as an prediction of 23 and an observed value of 25 events. This metric is used here due to its obvious interpretation and common usage in the assessment of predictive models.
  
  The second goodness of fit metric used in this study is called the Logarithmic Score. This metric is not as straightforward as the MAE, but it has qualities that make is well-suited to count-based predictions. The intuition of the Logarithmic Score is as follows: 'What is the likelihood of the observed count given the predicted count. More descriptively stated: if the model predicts 10 events and the observed count is 7 events, then what is the probability of observing those 7 events if the prediction of 10 is indeed the correct number. In this way, the Logarithmic Score measures the deviance between the predicted and observed counts. Specifically, this is measured by calculating the probability density of the observed value from a Poisson distribution centered on the predicted value. The goodness of fit measures below report the negative log of the probability density so that the value should always be minimized. In the results portion of this report, the Logarithmic Score is converted back to a probability and aggregated. The result is a score that is interpreted as the 'average likelihood that the observed counts are true given the predicted maltreatment counts. Closer to one means a higher relative likelihood, 0.5 equates to maximum uncertainty, and a value near zero signifies very little likelihood.
  
### Accuracy and generalization tradeoff
  
The purpose of the 10FCV and the goodness of fit metrics is to assess model errors on average and across space. A model that perfectly predicts the observed event counts for each fishnet grid cell would be very accurate, but would not generalize well to other cells because exposure changes across the city. Conversely, a model that predicts the same count of maltreatment events for every cell would generalize well, but not be relevant to the conditions of any one cell. 10FCV and associated metrics help establish a balance between model accuracy and model generalization. Given the purpose of this study, it is important to create a model that is accurate enough to give confidence, but general enough to be applicable in areas where few cases are documented.

## Results 

### Average goodness of fit results
  
  The table below displays the goodness of fit metrics for each of the sub-models and the meta-model. Mean and standard deviation of different metrics are calculated. Means are taken to describe relative goodness of fit across each held out neighborhood. Standard deviations are taken to describe the variation in goodness of fit across each held out neighborhood. If the model generalizes well across neighborhoods, then the standard deviation should be relatively low. 
  
  
```{r include = TRUE}
  Model_Error_Results_table
```
  
R2 or R Squared is a traditional measure of goodness of fit. Although typically not used to evaluate count outcomes, we include it here because it will be familiar to many readers. 
  
MAE or Mean Absolute Error is the absolute difference between the observed maltreatment counts and predicted counts. The meta-model MAE equates to $0.979$ on average. The relatively high standard deviation of MAE suggests that greater errors can be found certain places, namely those with very high maltreatment counts.
  
  RMSE or Root Mean Squared Error is the standard deviation of the prediction error. Like MAE, RMSE is reported on the scale of the dependent variable, but it varies in that the metric is weighted heavily by errors of high magnitude. 
  
  For the Logarithmic Score (logdev) the mean is `r round(meta_log_mean,3)` with a standard deviation of `r round(meta_log_sd, 3)`. This equates to a 95% confidence interval between `r meta_log_error_lower` and `r meta_log_error_upper` for the population average. The intuition of this result is that on average, the probability that the model estimates are correct given the documented maltreatment counts is between `r meta_log_error_lower` and `r meta_log_error_upper`. While the population average of errors from independent LOGOCV estimates is helpful for assessing how the model generalized, it is equally important to know how these errors are distributed both statistically and across space.
  
  Of note in the above table is the reduction in not only MAE and logdev but perhaps more importantly is a reduction in the standard deviation in those metrics across all of the **51 tracts**. The meta-model results in an average MAE of `r round(meta_MAE_mean, 3)` with a standard deviation of `r round(meta_MAE_sd, 3)`. The 95% confidence interval for the meta-model MAE across the entire population of neighborhoods is between `r meta_MAE_error_lower` and `r meta_MAE_error_upper`. Since MAE is on the scale of absolute count of maltreatment events, this means that the population average MAE is less than one incident.
  
  Figure X.X visualizes predicted vs. observed maltreatment event counts for the meta-model. The black line represents a perfect fit while the blue line represents the predicted fit. This plot provides visual evidence of an accurate model. Nevertheless, the plot also shows that the model errors are much higher for the highest observed counts. In other words, the model fits most of the data well but breaks down in grid cells with far greater counts. As we discuss below, this has some ramifications with respect to generalizability.
  
```{r include = TRUE, fig.align = "center"}
  plot_fold_pred(ens_cv_tbl$pred, ens_cv_tbl$test_y, type = "fit") +
    labs(x = "Observed Maltreatment Counts",
         y = "Predicted Maltreatment Counts",
         title = "Predicted vs. observed maltreatment counts",
         caption = "Figure 6.1") +
    plotTheme() +
    theme(panel.border = element_blank())
```

Next figure plots the log-deviance and MAE by the deciles for a visual comparison between the implemented methods. 
  
```{r decile_plots, include = TRUE, fig.align = "center", fig.height= 5}
cowplot::plot_grid(LOGDEV_MODEL_ERROR_BY_DECILE_plot,  MAE_MODEL_ERROR_BY_DECILE_plot, ncol = 1, align = "hv", axis = "lrbt")
```

### Predicted Values and MAE maps
  
  Figure below visualizes predicted vs. observed maltreatment event counts for the meta-model. The black line represents a perfect fit while the blue line represents the predicted fit. This plot provides visual evidence of an accurate model. Nevertheless, the plot also shows that the model errors are much higher for the highest observed counts. In other words, the model fits most of the data well but breaks down in grid cells with far greater counts. As we discuss below, this has some ramifications with respect to generalizability.

```{r combinedpredplot, include = TRUE, fig.height=12, cache = T}
cowplot::plot_grid(POISSON_MODEL_PREDICTION_MAP_plot, RF_MODEL_PREDICTION_MAP_plot, SARLM_MODEL_PREDICTION_MAP_plot, META_MODEL_PREDICTION_MAP_plot, ncol = 1, align = "hv", axis = "lrbt")

## Removed META_MODEL_PREDICTION_MAP_plot
```


### Generalizability

Further complementing these findings, Figure X.X shows the goodness of fit metrics broadened to the tract level for the meta-model estimates. These goodness of fit indicators were created by way of LOGOCV. Generally speaking, the MAE and Logarithmic Score metrics follow a similar pattern with higher errors in tracts with higher rates of maltreatment events. 

<span style="color:red"> If the model was perfectly generalizable, model errors by tract would be randomly distributed. The map in Figure X.X shows that MAE clusters slightly, particularly in tracts in the southeast of the city. </span>

<!-- A Global Moran's I test confirms the clustering of errors. -->

  
```{r include = TRUE, fig.width=12, fig.height=5}
  cowplot::plot_grid(LOGDEV_BY_NEIGHBORHOOD_plot,MAE_BY_NEIGHBORHOOD_plot,align = "h")
```
  

### Random Forest: Feature importance 
  
Next, we try to get under the hood of the model. We do this first, by visualizing feature importance. The below plot visualizes 'feature importance' for the Random Forest sub-model, showing which features make the greatest contribution in predicting maltreatment. We caution the reader to consider these relationships the result of correlation, not causation. 
  
```{r include = TRUE, fig.height=10, fig.width=10}
RF_VARIMP_PLOT
```

### Poisson GLM: Coefficients 

For a Poisson GLM, the exponents of coefficients are equal to the incidence rate ratio (relative risk). 

```{r include = TRUE, fig.height=10, fig.width=10}
POISSON_GLM_COEFF_plot
```


## ACS Variables: Stat Area Category Plot 

We looked at poverty (population struggling) and non-whites rates by census tracts, classify by quantiles, and plot the spatial distribution (here '0' is less and '1' is more). 

```{r include = TRUE, fig.height= 4}
STAT_AREA_CATEGORY_plot
```

### Census-tract typology comparison
####  Model Errors by Poverty and Non-white percentage

Next, we aggreate mean errors to statistical areas (med_dev, and med_MAE), aggregate sum of Child maltreatment incidents (med_CPS) to statarea, and (a) group by poverty (pop-struggle) and get median of stat-area aggregate errors, and (b) group by nonwhite and get median of statarea aggregate errors. 


  Income and race are inextricably linked to many of the census and exposure features used in the model, but no variables directly measuring race or income are included in the models. While feature importance provides some glimpses into how the model predicts, the best way to understand the inner-workings of a model is to look for patterns in how it predicts. Our approach for doing so, tests how well the model generalizes across both rich and poor areal units as well as white and minority areal units. 
  
  Two census attributes are selected for these purposes including percent living below poverty and percent non-white. 
  
  Next, median meta-model predictions are calculated for each NSA and goodness of fit is compared between high and low areas. Table below lists the median Logarithmic Score for both the high and low classes for each of the census variables. If the model generalizes well to both tract typologies, the Logarithmic Score should be comparable across high and low categories. We find a small but non-negligible difference between the log-scores  between race-related categories across the city but slightly less so for poverty-categories. 
  

```{r}
poverty_aggregate_table <- poverty_aggregate %>%
  kable(., format = "html", digits = 3) %>% kable_styling(bootstrap_options = "striped", full_width = F)

nonwhite_aggregate_table <- nonwhite_aggregate %>%
  kable(., format = "html", digits = 3) %>% kable_styling(bootstrap_options = "striped", full_width = F)

poverty_aggregate_table
nonwhite_aggregate_table
```


## Comparing meta-model predictions to Kernel Density
  
Perhaps the strongest method for assessing the usefulness of a predictive model is to compare its predictive power to that of the current resource allocation strategy. Here we compare our model to another common spatial targeting algorithm - Kernel Density Estimation (KDE). 
  
KDE is a simple spatial interpolation technique that calculates 'predicted risk' by taking a weighted local density of maltreatment events. No risk/protective factors are used and no measures of statistical significance can be calculated. To compare between the meta-model predictions and KDE, predictions from both are divided into five risk categories for the purposes of comparison. We then overlay held out maltreatment events that were not used to fit the original model, and calculate the percent of observed maltreatment events that fall into each predicted risk category. 
  
Figure 1.5 maps the comparison. The KDE clearly picks up the main areas of recorded events, but also interpolates high predictions for maltreatment in the areas between and beyond. The meta-model is far more targeted. 
  
```{r include = TRUE, fig.width=10}
cowplot::plot_grid(REALTIVE_SENSITIVITY_KDE, REALTIVE_SENSITIVITY_PREDICTIONS, align = "h")
```
  
  Figure 1.6 formalizes the comparison in chart form. **The highest risk category risk category for the meta-model captures approximately 60% of the recorded maltreatment events, whereas the KDE captures only about 35%**. This suggests that the spatial risk model vastly outperforms KDE.
  
```{r include = TRUE, fig.width=8}
REALTIVE_RISK_BARPLOT_COMPARE_plot
```

# Align 

## Risk category population totals
    
The demand for child welfare services is related to the number of people living in high risk areas. Figure 2.1 shows that approximately 33,210 people live in the highest risk category, covering 15.8% of the total population. Another 28.1% of the population (59,221) lives in the second highest risk category, indicating, in total, over 44% of the population live in areas of potentially high demand for child welfare services.
    
```{r include = TRUE, fig.width=8, fig.align="center"}
popPerRiskPlot
```
 

## Is poverty related to predicted maltreatment events?
    
Figure 2.2 maps the weighted poverty rate by fishnet grid cell. How does the distribution of poverty relate to maltreatment events? 
      
```{r include = TRUE, fig.align="center"}
povertyRateMap
```
    
Figure 2.3 illustrates the relationship between poverty rate and predicted maltreatment count. The scatter plot shows that the correlation between poverty and predictive risk is marginal. This visual relationship is confirmed by a correlation coefficient of 0.15. The weak relationship persists even when the zero count grid cells are removed.
    
```{r include = TRUE, fig.width = 8, fig.align="center"}
povRatePredPlot
```

## Maltreatment risk and child fatalities

Figure 2.6 maps locations of child fatalities over the predicted maltreatment risk categories. The associated bar plot shows the majority of child fatalities are occurring in the highest risk categories.

```{r include = TRUE, fig.width=14, fig.height=7}
load("child_fatality_data_plot_0829.RData")
cowplot::plot_grid(fatalitiesMap, fatalitiesPlot, align = "hv", axis = "lrbt")
```

## Assign risk scores to protective land uses (DCFS facilities)

The maltreatment predictions suggest where education, outreach, and prevention efforts should occur. What resources are available at these locations? We answer this question using some of the original protective factors data gathered for the predictive model. Stakeholders can replicate this approach on a more finite list of sites that could host these interventions. 

We then calculate a relative measure of risk exposure for each DCFS facilities by drawing quarter mile buffers around each site and taking the mean count of predicted events. **Figure 2.5 plots these buffers and the relative measure of risk exposure. The table that follows lists the top 20 individual DCFS facilities sorted by type and mean predicted count.**


```{r include = TRUE, fig.width=10.5}
load("dcfs_facilities_plot_0925.RData")
facilitiesMap
```

The following table lists the ten most optimally located DCFS facilities based on mean predicted count of maltreatment events within a quarter mile.

```{r include = TRUE}
top_facilities
```

This process can be repeated for a specific list of sites, e.g. we can calculate relative measure of risk exposure for Child Care Centers. 

## Assign risk scores to protective land uses (childcare and resource centers)

**Figure 2.6 plots the relative measure of risk exposure for quarter mile buffers around child care centers.**


```{r include = TRUE, fig.width=10.5}
load("protective_facilities_plot_1003.RData")
childcareMap
```

The following table lists the 5 most optimally located childcare facilities based on mean predicted count of maltreatment events within a quarter mile.

```{r include = TRUE}
top_childcare
```

**Figure 2.7 plots the relative measure of risk exposure for quarter mile buffers around neighbourhood resource centers.**


```{r include = TRUE, fig.width=10.5}
resourcehomeMap
```

The following table lists the five most optimally located neighbourhood resource centers based on mean predicted count of maltreatment events within a quarter mile.

```{r include = TRUE}
top_resourcehomes
```

## Supplementary Material

### Correlation 

#### Positively correlated variables

```{r corrpos_plot,cache = TRUE, warning=FALSE, echo=FALSE, include = TRUE,fig.width = 12, fig.height = 8}
CORR_LINE_POSITIVE_FEATURE_plot
```

#### Negatively correlated variables

```{r corrneg_plot,cache = TRUE, warning=FALSE,echo=FALSE,include = TRUE, fig.width = 12, fig.height = 8}
CORR_LINE_NEGATIVE_FEATURE_plot
```

### Chossing a fishnet grid size

```{r CPS_COMPARE_FISHNET_GRID_SIZE_3x2_plot}

grid_seq <- c(500,1000,1500)
p_loc_l  <- vector(mode = "list", length = length(grid_seq))
p_hist_l <- vector(mode = "list", length = length(grid_seq))

for(i in seq_along(grid_seq)){
  cat(grid_seq[i], "\n")
  net_i <- st_make_grid(lr_tract, cellsize = grid_seq[i])
  net_agg_i <- aggregate(cps_dissolve, net_i, sum) %>% 
    mutate(value = ifelse(is.na(value),0,value))
  
  net_intersect_i <- st_intersects(lr_tract, net_agg_i) 
  # extract Little Rocks net cells based on intersect ID
  net_littlerock_i <- net_agg_i[unique(unlist(net_intersect_i)),]
  
  net_littlerock_i$class <- Hmisc::cut2(net_littlerock_i$value, g = 9)
  p_loc <- ggplot() + #ggmap(cps_base_map) +
    geom_sf(data = ll(net_littlerock_i), aes(fill = class), 
            color = NA, inherit.aes = FALSE, size = 0.5, alpha = 0.8) +
    scale_fill_viridis_d(na.value=NA,
                         name   = paste0("Values","\n[quantiles]"),
                         breaks = levels(net_agg_i$class),
                         labels = levels(net_agg_i$class)) +
    mapTheme()
  
  p_loc_l[[i]] <- p_loc
  
  p_hist <- ggplot(net_littlerock_i, aes(x=value)) +
    geom_histogram(bins = 30) +
    # scale_x_continuous(limits = c(-1,100)) +
    # scale_y_continuous(limits = c(0,15)) +
    labs(title = paste0("Cell Dimensions =\n",grid_seq[i]," ft sq")) +
    plotTheme()
  
  p_hist_l[[i]] <- p_hist
}

CPS_COMPARE_FISHNET_GRID_SIZE_3x2_plot <- grid.arrange(p_hist_l[[1]], p_hist_l[[2]], p_hist_l[[3]], p_loc_l[[1]], p_loc_l[[2]], p_loc_l[[3]], ncol = 3)

```




### Goodness-of-fit Tests 

```{r fitdistr_gof, fig.height=3, fig.align = 'center'}
number <- as.numeric(na.omit(fishnet_pop_cps$net_CPS_Accepted))
fitp <- fitdist(number,"pois", discrete = TRUE)
fitnb <- fitdist(number,"nbinom", discrete = TRUE)
cdfcomp(list(fitp,fitnb)) # plot
gof <- gofstat(list(fitp,fitnb))
```


```{r AIC_LINE_FITDISTR_plot, fig.height=3, fig.align = 'center'}
net_cell_dims <- seq(500,5000,50)
aic_results <- matrix(nrow=length(net_cell_dims), ncol = 3)
colnames(aic_results) <- c("cell_dim","pois","nbinom")
for(i in seq_along(net_cell_dims)){
  net <- st_make_grid(lr_tract,cellsize=net_cell_dims[i])
  
  cps_cnt <- aggregate(cps_dissolve, net, sum)
  
  number <- as.numeric(na.omit(cps_cnt$value))
  fitp <- fitdist(number,"pois", discrete = TRUE)
  fitnb <- fitdist(number,"nbinom", discrete = TRUE)
  gof <- gofstat(list(fitp,fitnb))
  aic_results[i,1] <- net_cell_dims[i]
  aic_results[i,2] <- as.numeric(gof$bic[1])
  aic_results[i,3] <- as.numeric(gof$bic[2])
}

AIC_LINE_FITDISTR_plot <- data.frame(aic_results) %>%
  gather(dist, aic, -cell_dim) %>%
  rename("Distribution" = dist) %>% 
  mutate(Distribution = case_when(
    Distribution == "nbinom" ~ "Negative Binomial",
    Distribution == "pois"   ~ "Poisson"
  )) %>% 
  ggplot(., aes(x = cell_dim, y = aic, group = Distribution, color = Distribution)) +
  geom_line() +
  labs(y = "AIC - goodness of fit",
       x = "Fishnet Cell Dimension (feet)") +
  plotTheme()

AIC_LINE_FITDISTR_plot
```

### Tract fixed effects 

```{r NEIGHBORHOOD_FOLDS_plot, cache = TRUE}
cv_sf <- left_join(og_dat, net_littlerock, by = "net_id") %>%
  st_as_sf() %>% dplyr::select(.block_id)

NEIGHBORHOOD_FOLDS_plot <- plot(cv_sf)
```

## Appendix : R Codes 


```{r packages-A, message=FALSE, warning=FALSE, cache=FALSE, echo=TRUE, eval = FALSE}
if(T){
  library("sf")            # Spatial data objects and methods
  library("mapview")       # Interactive Map Viewing
  library("ggmap")         # ggplot2 addon for base maps
  library("cowplot")
  library("spatstat")      # KDE and other spatial functions
  library("raster")        # cell-based spatial operations
  library("tidyverse")     # data manipulation framework
  library("Hmisc")         # using cut2() functions for ggplot legends
  library("fitdistrplus")  # Distribution fitting functions
  library("lubridate")     # Power tools for handling dates
  library("tidycensus")
  library("lwgeom")
  library("Hmisc")
  library("hrbrthemes")
  library("gridExtra")
  library("patchwork")
  library("spdep")         # KNN functions
  library("foreach")
  library("doParallel")
  library("corrplot")
  library("ranger")        # randomforest implimentation      
  library("glmnet")        # for Ridge and Lasso Regression
  library("knitr")         # for kable table
  library("kableExtra")
  library("FNN")           # KNN for CPS vs. NN plots
  library("groupdata2")
  library("htmltools")
  library("viridis")
  library("viridisLite")
}
```


```{r themes-A, echo=TRUE, eval = FALSE}
mapTheme <- function() {
  theme(
    plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
    plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
    plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.ticks = element_blank(),
    axis.line = element_blank(),
    legend.title = element_text(size = 10, family = "sans"),
    legend.text = element_text(size = 9, family = "sans"),
    panel.border = element_blank()
  )
}

plotTheme <- function() {
  theme(
    plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
    plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
    plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0), 
    axis.title.x = element_text(size = 10, family = "sans", face = "plain", hjust = 1, vjust = -0.5),
    axis.title.y = element_text(size = 10, family = "sans", face = "plain", hjust = 1, vjust = 1),
    axis.text = element_text(size = 7, family = "sans", face = "plain"),
    panel.background = element_blank(),
    panel.grid.minor = element_line(colour = "gray"),
    panel.grid.major = element_line(colour = "gray"),
    axis.ticks = element_blank(),
    legend.title = element_text(size = 10, family = "sans"),
    legend.text = element_text(size = 9, family = "sans"),
    axis.line = element_blank()
  )
}
```

```{r options-A, echo=TRUE, eval = FALSE}
if(T){
  mapviewOptions(basemaps = c("Stamen.TonerLite", "OpenStreetMap.DE"))
  base_dir = "C:/Users/jd033/Box/LR-Project"
  fishnet_grid_dim = 1000
  k_direction = 8 # 4 = rook, 8 = queen
  k_nearest_neighbors = 5
  # Either k (e.g. 5 or 10) or "LOOCV"
  n_folds = "LOOCV"
  # threshold quntile for statArea grouping
  stat_area_quantile = 0.60
  # Number of simulations for CPS vs. NN
  simulations = 1000
  # Number of neighbors for CPS vs. NN
  k = 5
  # random seed
  set.seed(11235)
}
```

```{r SOURCE-A, echo=TRUE, eval = FALSE}
## Source 

source('C:/Users/jd033/Box/Child Maltreatment/R-codes/FUNCTIONS_VAPAP_LR.R', echo = FALSE, keep.source = TRUE)
source('C:/Users/jd033/Box/Child Maltreatment/R-codes/FEA_CREATE_VARIABLES_LR_2.R', echo = TRUE, keep.source = TRUE)

## Can be also loaded via 
# load("Rdata/source_file_objects.RData")
```

### LR Tracts 

```{r neighborhoods-A, echo=TRUE, eval = FALSE}
## LR tracts data
lr_tract = var_list[["LR_Tracts_Working51"]]

TRACT_AREA_plot <- lr_tract %>%
    ggplot(aes(fill = Area)) + 
    geom_sf(color = NA) + 
    coord_sf(crs = 2765) + 
    scale_fill_viridis_c(option = "plasma") + 
    labs(title = "Area")

lr_tract_diss <- lr_tract %>%
  mutate(dissolve = 1) %>%
  # get rid of slivers
  st_buffer(., dist = 0.1) %>%
  group_by(dissolve) %>%
  summarise()

lr_rast_SP <- raster(as(lr_tract_diss, "Spatial"), nrows = 2000, ncol = 2000)
```

### Basemap

```{r basemap-A, echo=TRUE, eval = FALSE}

var_list[["CPS_Accepted"]] <-  var_list[["CM_LR_Matched_Centerline_3857"]]

idx_2 = which(var_names == "CM_LR_Matched_Centerline_3857")
var_list[[idx_2]] <- NULL

cps_base_map   <- get_stamenmap(bbox = c(left = -92.52091, bottom = 34.62606, right = -92.15494, top = 34.82195),
                                    maptype = "toner-lite")

# ggmap(cps_base_map)

## Alternative 

lr_base_map <- st_union(lr_tract) %>%
  ggplot()+geom_sf(aes(), fill = "grey85", color = NA, size = 1) +
  mapTheme()

### get CPS_Accepted values (add 1 column for dissolving)
cps_dissolve <- var_list[["CPS_Accepted"]] %>%
  mutate(value = 1) %>%
  dplyr::select(value)
```

### Count CPS incidents per net cell

```{r fishnet-A, echo=TRUE, eval = FALSE}
net <- st_make_grid(lr_tract, cellsize = fishnet_grid_dim) #%>%st_transform(2756)

# cps_dissolve %>% st_crs() == lr_tract %>% st_crs() 

# count CPS incidents per net cell - really just to get net raster into sf polygon format
net_agg <- aggregate(cps_dissolve, net , sum) %>%
    tibble::rowid_to_column(.,"net_id")

net_agg_vals = net_agg$value[!is.na(net_agg$value)]

# summary(net_agg_vals)

# list of net cells IDs that intersect with Little Rock
net_intersect <- st_intersects(lr_tract, net_agg)

# extract Little Rock net cells based on intersect ID
net_littlerock <- net_agg[unique(unlist(net_intersect)),]
net_hood <- st_join(net_littlerock, lr_tract, largest = TRUE)
listw <- nb2listw(poly2nb(as(net_littlerock, "Spatial"), queen = TRUE))

## Plot fishnet 

net_littlerock$value[is.na(net_littlerock$value)] <- 0

FISHNET_plot <- net_littlerock %>%
  ggplot(aes(fill = value)) + 
  geom_sf(color = "grey60") + 
  coord_sf(crs = 2765) + 
  scale_fill_viridis_c(option = "magma") + 
  labs(title = "CM per grid-cell")+ 
  plotTheme()

```

### Population and Other Census Data

```{r population_data-A, echo=TRUE, eval = FALSE}
acs <- var_list[["LR_BG_Tracts_ACS_DataJoined"]]

acs = acs %>% dplyr::select(Incident_C, TotPopSize, NLTotPop, PopDensity,Perc_Under,
                            Perc_Black, Perc_NonWh, Perc_Hispa, Perc_NonMa,
                            Perc_FHH,Perc_SingP,PercLowEdu, Perc_Rente,
                            Perc_PopUn, Perc_PopSt, Perc_NotIn, Perc_Publi,
                            PercHighHH, PercCollEd, Perc_OwnHo)

acs <- acs %>% rename( Incident_Count_sum = Incident_C,
                       Perc_Under18 = Perc_Under,
                       Perc_NonMarr_Fam_HH = Perc_NonMa,
                       Perc_SingPrnt_HH = Perc_SingP,
                       Perc_RenterOcc = Perc_Rente,
                       Perc_PopUnder18inPov = Perc_PopUn,
                       Perc_PopStrugg = Perc_PopSt,
                       Perc_NotInsured = Perc_NotIn, 
                       Perc_PublicInsure = Perc_Publi)


acs_pop <- acs %>% dplyr::select(TotPopSize)

## The number 2.29568e-5 is sq ft to acre conversion. 
## if you download from ACS using tidycensus, the variable name is "value", here it's TotPopSize.

acs_pop <- acs_pop %>%
  mutate(acre = as.numeric(st_area(acs)*2.29568e-5),
         # acre = units::set_units(acre, acre), 
         pop_acre_rate = TotPopSize / acre) 


POP_ACRE_RATE_plot <- acs_pop %>%
  ggplot(aes(fill = pop_acre_rate)) + 
  geom_sf(color = NA) + 
  coord_sf(crs = 2765) + 
  scale_fill_viridis_c(option = "magma") + 
  labs(title = "Population per acre")+ 
  plotTheme()
```

```{r t_intersection-A, echo=TRUE, eval = FALSE}
net_blocks_intersect <- st_intersection(acs_pop, net_littlerock)

# group by cell and calc block stats.
net_blocks_intersect <- net_blocks_intersect %>%
  mutate(intersect_area_acres = as.numeric(st_area(net_blocks_intersect)*2.29568e-5)) %>%
  group_by(net_id) %>%
  mutate(cnt = n(),
         pcnt_of_block = intersect_area_acres/acre,
         intersect_pop = TotPopSize * pcnt_of_block) %>%
  arrange(net_id)
```

### Summarize population 

```{r, summarise_pop-A, echo=TRUE, eval = FALSE}
## Summarize pop 
fishnet_pop <- net_blocks_intersect %>% # xcc
  group_by(net_id) %>%
  summarise(net_pop = sum(intersect_pop)) %>%
  filter(net_pop > 0)   # <-  zeros or no zeros!!!!

BASIC_FISHNET_plot <-fishnet_pop %>%
  ggplot(aes(fill = net_pop)) + 
  geom_sf(color = NA) + 
  scale_fill_viridis_c(option = "plasma") + 
  labs(title = "Net Pop")

######### MAKE NET AND RATE FOR ALL CPS VARS
CPS_vars <- grep("CPS_",names(var_list), value = TRUE)
CPS_agg <- NULL

for(i in seq_along(CPS_vars)){
  var_name <- paste0("net_",CPS_vars[i])
  cat(var_name,"\n")
  
  CPS_dat <- var_list[[CPS_vars[i]]] %>%
    mutate(value = 1) %>%
    dplyr::select(value)
  
  fishnet_CPS_var <- aggregate(x = CPS_dat, by = fishnet_pop, FUN = sum) %>%
    st_drop_geometry() %>%
    mutate(Feature = var_name) %>%
    dplyr::select(Feature,value)
  
  CPS_agg <- rbind(CPS_agg, fishnet_CPS_var)
}

CPS_agg <- CPS_agg %>%
  mutate(id = rep(seq(1:nrow(fishnet_pop)),length(CPS_vars))) %>%
  spread(Feature, value) %>%
  dplyr::select(-id) %>%
  mutate(geometry = fishnet_pop$geometry) %>%
  st_as_sf()

#### Spatial join of fishnet_pop and fishnet_cps to then calculate rate for all CPS features

fishnet_pop_cps <- st_join(fishnet_pop, CPS_agg, join = st_equals) %>%
  mutate_at(vars(paste0("net_",CPS_vars)), funs(rate = ./(net_pop/100)))  %>% # cps per 100 person
  # rename_at(vars( contains( "_rate")), .funs = list(paste("rate", gsub("net_|_rate", "", .), sep = "_"))) %>% 
  replace(is.na(.), 0) # replace NA with zero

fishnet_coords <- fishnet_pop_cps %>%
  st_centroid() %>%
  st_coordinates() %>%
  as.matrix()
```

### CM Count by fishnet

```{r CPS_COUNT_BY_FISHNET_plot-A, echo=TRUE, eval = FALSE}
fishnet_pop_cps_cut <- fishnet_pop_cps %>%
  mutate(net_CPS_Accepted = ifelse(is.na(net_CPS_Accepted), 0, net_CPS_Accepted)) %>% 
  make_cuts(., "net_CPS_Accepted", cuts = "breaks", n_breaks = 10)

CPS_COUNT_BY_FISHNET_PLOT <- lr_base_map + #ggplot() + #ggmap(cps_base_map) +
  geom_sf(data = ll(fishnet_pop_cps_cut), aes(fill = cut_val), inherit.aes = FALSE, color = NA, alpha = 0.8) +
  labs(title = "CPS count per\nfishnet cell") +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "CPS Count") +
  mapTheme() +
  theme(plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
        plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
        plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
        axis.line = element_blank(),
        legend.title = element_text(size = 10, family = "sans"),
        legend.text = element_text(size = 9, family = "sans"))
```

```{r CPS_RATE_BY_FISHNET_plot-A, echo=TRUE, eval = FALSE}
fishnet_pop_cps <- fishnet_pop_cps %>% rename(rate_CPS_Accepted = rate)

fishnet_pop_cps_rate_cut <- fishnet_pop_cps %>%
  mutate(rate_CPS_Accepted = ifelse(is.na(rate_CPS_Accepted), 0, rate_CPS_Accepted)) %>% 
  make_cuts(., "rate_CPS_Accepted", cuts = "breaks", n_breaks = 10)

CPS_RATE_BY_FISHNET_PLOT <- ggplot() + #ggmap(cps_base_map) +
  geom_sf(data = ll(fishnet_pop_cps_rate_cut), aes(fill = cut_val), inherit.aes = FALSE, color = NA, alpha = 0.8) +
  labs(title = "Child Protective Service rate\nper 100 people") +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "CPS Rate\nper 100") +
  mapTheme() +
  theme(plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
        plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
        plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
        axis.line = element_blank(),
        legend.title = element_text(size = 10, family = "sans"),
        legend.text = element_text(size = 9, family = "sans"))
```

### CPS counts by month and year

```{r CPS_Count_Month_Year_table-A, echo=TRUE, eval = FALSE}
CPS_Counts_Year_table  <- table(lubridate::year(var_list[["CPS_Accepted"]]$Referral_D))
CPS_Counts_Month_table <- table(lubridate::month(var_list[["CPS_Accepted"]]$Referral_D))

```

### CPS histogram by date 

```{r CPS_HIST_BY_DATE_plot-A, echo=TRUE, eval = FALSE}
CPS_by_year <- lubridate::year(var_list[["CPS_Accepted"]]$Referral_D) %>%
  data.frame(year = .)
CPS_HIST_BY_DATE <- ggplot(CPS_by_year, aes(x = year)) +
  geom_histogram() +
  plotTheme()
```


### CPS points by month plot 

```{r CPS_POINT_BY_MONTH_plot-A, echo=TRUE, eval = FALSE}
months <- c("January", "February", "March", "April", 
            "May", "June", "July","August", 
            "September", "October", "November", "December")
cps <- var_list[["CPS_Accepted"]] %>%
  mutate(year  = lubridate::year(Referral_D),
         month = lubridate::month(Referral_D),
         month = months[month],
         month = fct_relevel(month, months))

CPS_POINT_BY_MONTH_plot <- ggplot()+#ggmap(cps_base_map) +
  geom_point(data = data.frame(st_coordinates(ll(cps)), year = cps$year), 
             aes(x=X, y=Y, color = as.factor(year)), size=1.5, alpha = 0.8) +
  scale_color_viridis_d(name = "Year") +
  labs(title = "CPS Accepted in Little Rock, AR by Year",
       caption = "source: **************") +
  facet_wrap(~year) +
  mapTheme() +
  theme(
    legend.key = element_rect(fill = "white"),
    strip.text = element_text(face = "plain", size = 11),
    legend.position = c(0.85, 0.25) # or "none
  )

```

### CPS KDE by Year plot 

```{r CPS_KDE_BY_YEAR_plot-A, echo=TRUE, eval = FALSE}

variable = "year"
values <- unique(cps[[variable]])
year_dat <- list()
brks <- 9
window_cps <- get_window(cps, buff_dist = 10000)
for(i in seq_along(values)){
  dat <- filter(cps, !!as.name(variable) == values[i])
  points.ppp <- as.ppp(st_coordinates(ll(dat)),window_cps)
  densityRaster <- raster(density(points.ppp, scalekernel=TRUE, sigma = 0.005))
  dens_data <- gplot_data(densityRaster, maxpixels = 2500) %>%
    mutate(!!as.name(variable) := values[i])
  year_dat[[i]] <- dens_data
}
year_dat <- do.call(rbind, year_dat)

CPS_KDE_BY_YEAR_plot <- ggplot() + #ggmap(cps_base_map) +
  geom_tile(data = year_dat, 
            aes(x,y,fill = as.factor(ntile(value,brks)), 
                group = !!as.name(variable)), alpha=0.8) +
  scale_fill_viridis_d(name = variable) +
  labs(title = "CPS accepted in Little Rock, VA by year",
       caption = "Figure 5.2") +
  facet_wrap(vars(!!as.name(variable))) +
  mapTheme() +
  theme(
    legend.key = element_rect(fill = "white"),
    strip.text = element_text(face = "plain", size = 11, hjust = 0),
    strip.background = element_rect(fill = "white"),
    legend.position = "none"
  )
```


### CPS trend by month and year 

```{r CPS_TREND_BY_MONTH_YEAR_plot-A, echo=TRUE, eval = FALSE}
# CPS_KDE_BY_YEAR_plot

CPS_by_year_month <- st_drop_geometry(var_list[["CPS_Accepted"]]) %>%
  mutate(month = lubridate::month(Referral_D),
         year  = lubridate::year(Referral_D))%>%
  dplyr::select(month, year) %>%
  group_by(month, year) %>%
  mutate(m_count = n()) %>%
  distinct() %>%
  ungroup()

CPS_TREND_BY_MONTH_YEAR_plot <- ggplot(CPS_by_year_month, aes(x = year, y = m_count)) +
  geom_point() +
  geom_smooth(method = lm, formula = y ~ splines::bs(x, 3)) +
  labs(y="Incidents per month") +
  plotTheme()

```

### CPS Line Agg by Month

```{r CPS_LINE_AGG_BY_MOTNH_plot-A, echo=TRUE, eval = FALSE}
CPS_agg_by_month <- st_drop_geometry(var_list[["CPS_Accepted"]]) %>%
  mutate(month = lubridate::month(Referral_D),
         year  = lubridate::year(Referral_D))%>%
  group_by(month) %>%
  summarise(count = n())

CPS_LINE_AGG_BY_MOTNH_plot <- ggplot(CPS_agg_by_month, aes(x = month, y = count)) +
  scale_x_continuous(breaks = seq(1,12), labels = seq(1,12)) +
  geom_line() +
  plotTheme()

```

```{r CPS_LINE_NORMALIZED_plot-A, echo=TRUE, eval = FALSE}
CPS_normalized_by_month <- st_drop_geometry(var_list[["CPS_Accepted"]]) %>%
  mutate(month = lubridate::month(Referral_D),
         year  = lubridate::year(Referral_D)) %>%
  group_by(year, month) %>%
  summarise(m_total = n()) %>%
  arrange(month, year) %>%
  dplyr::select(month, year, m_total) %>%
  ungroup() %>%
  group_by(month) %>%
  mutate(m_mean = mean(m_total),
         m_sd   = sd(m_total),
         m_z    = (m_total - m_mean) / m_sd)

CPS_LINE_NORMALIZED_plot <- ggplot(CPS_normalized_by_month, aes(x = as.factor(month), 
                                                                y = m_z, group = year, 
                                                                color = as.factor(year))) +
  geom_line() +
  geom_hline(yintercept = 0, color = "gray20", linetype = "dashed") +
  scale_color_viridis_d(name = "year") +
  labs(x = "month") +
  scale_y_continuous(limits = c(-2,2)) +
  plotTheme()

CPS_LINE_NORMALIZED_plot
```

### CPS Calendar plot 

```{r CPS_CALENDAR_plot-A, echo=TRUE, eval = FALSE}
CPS_agg_cal <- st_drop_geometry(var_list[["CPS_Accepted"]]) %>%
  mutate() %>%
  mutate(day = factor(weekdays(Referral_D,T),
                      levels = rev(c("Mon", "Tue", "Wed", "Thu","Fri", "Sat", "Sun"))),
         week = week(Referral_D),
         month = month(Referral_D),
         year  = year(Referral_D)) %>%
  dplyr::select(day, week, month, year) %>%
  group_by(day, week, month, year) %>%
  summarise(day_cnt = n()) %>%
  complete(day, week, month, year) 

CPS_CALENDAR_plot <- ggplot(CPS_agg_cal, aes(x = week, y = day, fill = day_cnt)) +
  viridis::scale_fill_viridis(name="Incidents",
                              option = 'C',
                              direction = 1,
                              na.value = "gray90") +
  geom_tile(color = 'white', size = 0.1) +
  facet_wrap('year', ncol = 1) +
  scale_x_continuous(
    expand = c(0, 0),
    breaks = seq(1, 52, length = 12),
    labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
               "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")) +
  theme_ipsum_rc()

```

### CPS compare fishnet grid size 

```{r CPS_COMPARE_FISHNET_GRID_SIZE_3x2_plot-A, echo=TRUE, eval = FALSE}
grid_seq <- c(500,1000,1500)
p_loc_l  <- vector(mode = "list", length = length(grid_seq))
p_hist_l <- vector(mode = "list", length = length(grid_seq))
for(i in seq_along(grid_seq)){
  cat(grid_seq[i], "\n")
  net_i <- st_make_grid(lr_tract, cellsize = grid_seq[i])
  net_agg_i <- aggregate(cps_dissolve, net_i, sum) %>% 
    mutate(value = ifelse(is.na(value),0,value))
  
  net_intersect_i <- st_intersects(lr_tract, net_agg_i) 
  # extract Little Rocks net cells based on intersect ID
  net_littlerock_i <- net_agg_i[unique(unlist(net_intersect_i)),]
  
  net_littlerock_i$class <- Hmisc::cut2(net_littlerock_i$value, g = 9)
  p_loc <- ggplot() + #ggmap(cps_base_map) +
    geom_sf(data = ll(net_littlerock_i), aes(fill = class), 
            color = NA, inherit.aes = FALSE, size = 0.5, alpha = 0.8) +
    scale_fill_viridis_d(na.value=NA,
                         name   = paste0("Values","\n[quantiles]"),
                         breaks = levels(net_agg_i$class),
                         labels = levels(net_agg_i$class)) +
    mapTheme()
  
  p_loc_l[[i]] <- p_loc
  
  p_hist <- ggplot(net_littlerock_i, aes(x=value)) +
    geom_histogram(bins = 30) +
    # scale_x_continuous(limits = c(-1,100)) +
    # scale_y_continuous(limits = c(0,15)) +
    labs(title = paste0("Cell Dimensions =\n",grid_seq[i]," ft sq")) +
    plotTheme()
  
  p_hist_l[[i]] <- p_hist
}

CPS_COMPARE_FISHNET_GRID_SIZE_3x2_plot <- grid.arrange(p_hist_l[[1]], p_hist_l[[2]], p_hist_l[[3]], p_loc_l[[1]], p_loc_l[[2]], p_loc_l[[3]], ncol = 3)

CPS_COMPARE_FISHNET_GRID_SIZE_3x2_plot 
```

```{r fitdistr_gof-A, echo=TRUE, eval = FALSE}
number <- as.numeric(na.omit(fishnet_pop_cps$net_CPS_Accepted))
fitp <- fitdist(number,"pois", discrete = TRUE)
fitnb <- fitdist(number,"nbinom", discrete = TRUE)
cdfcomp(list(fitp,fitnb)) # plot
gof <- gofstat(list(fitp,fitnb))
```


### AIC calculation for Poisson and Negative Binomial 

```{r AIC_LINE_FITDISTR_plot-A, echo=TRUE, eval = FALSE}
net_cell_dims <- seq(500,5000,50)
aic_results <- matrix(nrow=length(net_cell_dims), ncol = 3)
colnames(aic_results) <- c("cell_dim","pois","nbinom")
for(i in seq_along(net_cell_dims)){
  net <- st_make_grid(lr_tract,cellsize=net_cell_dims[i])
  
  cps_cnt <- aggregate(cps_dissolve, net, sum)
  
  number <- as.numeric(na.omit(cps_cnt$value))
  fitp <- fitdist(number,"pois", discrete = TRUE)
  fitnb <- fitdist(number,"nbinom", discrete = TRUE)
  gof <- gofstat(list(fitp,fitnb))
  aic_results[i,1] <- net_cell_dims[i]
  aic_results[i,2] <- as.numeric(gof$bic[1])
  aic_results[i,3] <- as.numeric(gof$bic[2])
}

AIC_LINE_FITDISTR_plot <- data.frame(aic_results) %>%
  gather(dist, aic, -cell_dim) %>%
  rename("Distribution" = dist) %>% 
  mutate(Distribution = case_when(
    Distribution == "nbinom" ~ "Negative Binomial",
    Distribution == "pois"   ~ "Poisson"
  )) %>% 
  ggplot(., aes(x = cell_dim, y = aic, group = Distribution, color = Distribution)) +
  geom_line() +
  labs(y = "AIC - goodness of fit",
       x = "Fishnet Cell Dimension (feet)") +
  plotTheme()

```

### Protective and Risk Variables 

```{r risk_protective_var_list-A, echo=TRUE, eval = FALSE}
protective_names <-  c("Banks",
                       "GrocerySuperMarket",
                       "HighSchoolsPublic",
                       "HotelMotel",
                       "ChildCareServices",
                       "ChildYouthServices",
                       "CivilSocialOrgs",
                       "Hospitals",
                       "NeighborhoodResourceCenters",
                       "PoliceFacilities",
                       "ReligiousOrgs")

risk_names <- c( "CRIME_THEFT OF PROPERTY FELONY", 
                 "CRIME_BURGLARY - RESIDENTIAL",
                 "CRIME_AGGRAVATED ASSAULT", 
                 "CRIME_TERRORISTIC ACT",                              
                "CRIME_THEFT OF PROPERTY MISD",                             
                "CRIME_RAPE",                                               
                "CRIME_BATTERY 2ND DEGREE",                                 
                "CRIME_DOMESTIC BATTERING 2ND DEGREE",                      
                "CRIME_BREAKING OR ENTERING VEHICLE" ,                      
                "CRIME_AGGRAVATED ROBBERY (INDIVIDUAL)",                    
                "CRIME_ROBBERY (INDIVIDUAL)" ,                              
                "CRIME_AGGRAVATED ASSAULT ON AN FAMILY OR HOUSEHOLD MEMBER",
                "CRIME_BURGLARY COMMERCIAL" ,                               
                "CRIME_BATTERY 1ST DEGREE",
                "BarberAndBeautyShops",
                "BusStops",
                "CheckCashingAndPawn",
                "FastFoodAndBeverage",
                "GasStationAndConvMart",
                "HotelMotel",
                "LiquorStores",
                "MajorDeptRetailDiscount",
                "MixedDrink_BarRestClub",
                "Rental_MobileHomes",
                "Rental_SingleToQuad",
                "Rentals_Apts_LessThan100units",
                "Rentals_Apts_Over100units",
                "TattooPiercing",
                "Unsafe_Vacant_BldgsNEW")

risk_var_list <- var_list[grep(paste(risk_names,collapse="|"), names(var_list), value = TRUE)]
protective_var_list <- var_list[grep(paste(protective_names,collapse="|"), names(var_list), value = TRUE)]
```

```{r risk_points_KDE_compute-A, echo=TRUE, eval = FALSE}
risk_plot_dat <- list()
brks <- 9
window_cps <- get_window(cps, buff_dist = 10000)
for(i in seq_along(risk_var_list)){
  var_dat <- risk_var_list[[i]]
  points.ppp <- as.ppp(st_coordinates(ll(var_dat)),window_cps)
  densityRaster <- raster(density(points.ppp, scalekernel=TRUE, sigma = 0.005))
  dens_data <- gplot_data(densityRaster, maxpixels = 2500) %>%
    mutate(variable = names(risk_var_list)[i])
  risk_plot_dat[[i]] <- dens_data
}
risk_plot_dat <- do.call(rbind, risk_plot_dat)

# one-liner to extract all 'geometry' cols from list and rbind
risk_compile <- sf::st_as_sf(data.table::rbindlist(lapply(risk_var_list, '[', "geometry")))
risk.points.ppp <- as.ppp(st_coordinates(ll(risk_compile)),window_cps)
risk_densityRaster <- raster(density(risk.points.ppp, scalekernel=TRUE, sigma = 0.005))
risk_aggregate_plot_data <- gplot_data(risk_densityRaster, maxpixels = 2500) %>%
  mutate(variable = "Risk")
```

```{r RISK_KDE_FACET_PLOT-A, echo=TRUE, eval = FALSE}
## KDE Risk 
# risk_plot_xy <- risk_plot_dat %>% dplyr::select(x,y)
# library(proj4)
# proj4string <- "+proj=utm +zone=19 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs "
# pj = project(risk_plot_xy, proj4string, inverse=TRUE) 
# risk_latlon <- data.frame(lat=pj$y, lon=pj$x)
# risk_plot_latlon = cbind(risk_plot_dat, risk_latlon)

RISK_KDE_FACET_PLOT <- ggplot() + #ggmap(cps_base_map) +
  geom_tile(data = risk_plot_dat, 
            aes(x,y, fill = as.factor(ntile(value,brks)), 
                group = variable), alpha=0.8) +
  scale_fill_viridis_d(name = variable) +
  facet_wrap(~variable) +
  labs(title = "Spatial density of risk factors",
       caption = "Figure 5.4") +
  mapTheme() +
  theme(
    legend.key = element_rect(fill = "white"),
    strip.text = element_text(face = "plain", size = 11, hjust = 0),
    legend.position = "none",
    strip.background = element_rect(fill = "white")
  )

# RISK_KDE_FACET_PLOT

RISK_KDE_PLOT <- ggplot() + #ggmap(cps_base_map) +
  geom_tile(data = risk_aggregate_plot_data, 
            aes(x,y,fill = as.factor(ntile(value,brks)), 
                group = variable), alpha=0.6) +
  scale_fill_viridis_d(name = variable) +
  #facet_wrap(~variable) +
  mapTheme() +
  theme(
    legend.key = element_rect(fill = "white"),
    strip.text = element_text(face = "plain", size = 11),
    legend.position = "none"
  )

# RISK_KDE_PLOT
```

```{r protective_points_KDE_compute-A, echo=TRUE, eval = FALSE}
protective_plot_dat <- list()
window_cps <- get_window(cps, buff_dist = 10000)
for(i in seq_along(protective_var_list)){
  var_dat <- protective_var_list[[i]]
  points.ppp <- as.ppp(st_coordinates(ll(var_dat)),window_cps)
  densityRaster <- raster(density(points.ppp, scalekernel=TRUE, sigma = 0.005))
  dens_data <- gplot_data(densityRaster, maxpixels = 2500) %>%
    mutate(variable = names(protective_var_list)[i])
  protective_plot_dat[[i]] <- dens_data
}
protective_plot_dat <- do.call(rbind, protective_plot_dat)

# one-liner to extract all 'geometry' cols from list and rbind
protective_compile <- sf::st_as_sf(data.table::rbindlist(lapply(protective_var_list, '[', "geometry")))
protective.points.ppp <- as.ppp(st_coordinates(ll(protective_compile)),window_cps)
protective_densityRaster <- raster(density(protective.points.ppp, scalekernel=TRUE, sigma = 0.005))
protective_aggregate_plot_data <- gplot_data(protective_densityRaster, maxpixels = 2500) %>%
  mutate(variable = "Protective")
```



```{r PROTECTIVE_KDE_FACET_PLOT-A, echo=TRUE, eval = FALSE}
PROTECTIVE_KDE_FACET_PLOT <- ggplot() + #ggmap(cps_base_map) +
  # geom_point(data = data.frame(st_coordinates(ll(cps)),
  #                              month = cps[[variable]]),
  #            aes(x=X, y=Y), size = 1, color = "gray30", alpha = 0.75) +
  geom_tile(data = protective_plot_dat, 
            aes(x,y,fill = as.factor(ntile(value,brks)), 
                group = variable), alpha=0.8) +
  scale_fill_viridis_d(name = variable) +
  facet_wrap(~variable) +
  labs(title = "Spatial density of protective factors",
       caption = "Figure 5.3") +
  mapTheme() +
  theme(
    legend.key = element_rect(fill = "white"),
    strip.text = element_text(face = "plain", size = 11, hjust = 0),
    legend.position = "none",
    strip.background = element_rect(fill = "white")
  )

PROTECTIVE_KDE_PLOT <- ggplot()+  #ggmap(cps_base_map) +
  geom_tile(data = protective_aggregate_plot_data, 
            aes(x,y,fill = as.factor(ntile(value,brks)), 
                group = variable), alpha=0.6) +
  scale_fill_viridis_d(name = variable) +
  #facet_wrap(~variable) +
  mapTheme() +
  theme(
    legend.key = element_rect(fill = "white"),
    strip.text = element_text(face = "plain", size = 11),
    legend.position = "none"
  )

# PROTECTIVE_KDE_PLOT
```

```{r spatial_weights_lattice-A, echo=TRUE, eval = FALSE}
fishnet_knn <- knn2nb(knearneigh(fishnet_coords, k_direction))
fishnet_Weights <- nb2listw(fishnet_knn, style="W")
localMorans  <- as.data.frame(localmoran(fishnet_pop_cps$net_CPS_Accepted, fishnet_Weights))
globalMorans <- moran.mc(fishnet_pop_cps$net_CPS_Accepted, fishnet_Weights, nsim=999)
```

```{r GLOBAL_MORANS_PERMUTATION_plot-A, echo=TRUE, eval = FALSE}
GLOBAL_MORANS_PERMUTATION_plot <- ggplot(data.frame(res = globalMorans$res)[1:999,,0], aes(res)) + 
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = globalMorans$statistic), colour = "red",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="Observed and permuted Moran's I", 
       x = "Simulated Moran's I Value") +
  plotTheme()
```

```{r Morans_i_p_join-A, echo=TRUE, eval = FALSE}
fishnet_pop_cps_morans <- fishnet_pop_cps
fishnet_pop_cps_morans$Ii <- localMorans$Ii
fishnet_pop_cps_morans$pvalue <- localMorans$`Pr(z > 0)`
fishnet_pop_cps_morans <- cbind(fishnet_coords, fishnet_pop_cps_morans)
```

```{r MORANS_I_P_plot-A, echo=TRUE, eval = FALSE}
fishnet_pop_cps_morans_cut <- make_cuts(fishnet_pop_cps_morans, "net_CPS_Accepted",
                                        cuts = "breaks", n_breaks = 10)

## Next chunk 
plot_cps <- lr_base_map + #ggplot() + #ggmap(cps_base_map) +
  geom_sf(data = ll(fishnet_pop_cps_morans_cut), aes(fill = cut_val),
          color = NA, inherit.aes = FALSE, alpha = 0.8) +
  scale_fill_viridis_d(na.value=NA, name = "Maltreatment\nEvents") +
  labs(title = "Panel 1",
       subtitle = "CPS count by fishnet") +
  mapTheme() +
  theme(plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
        plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
        plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
        axis.line = element_blank(),
        legend.title = element_text(size = 10, family = "sans"),
        legend.text = element_text(size = 9, family = "sans"))

Ii_cut <- fishnet_pop_cps_morans %>%
  mutate(Ii_cut_val = as.character(Hmisc::cut2(.$Ii, 
                                               cuts = as.numeric(quantile(round(fishnet_pop_cps_morans$Ii,2), 
                                                                          na.rm=T, p = seq(0,1,0.25))))))
plot_Ii <- lr_base_map + #ggplot() + #ggmap(cps_base_map) +
  geom_sf(data = ll(Ii_cut), aes(fill = Ii_cut_val),
          color = NA, inherit.aes = FALSE, alpha = 0.8) +
  scale_fill_viridis_d(na.value=NA, name = "I value", option = "D") +
  labs(title = "Panel 2",
       subtitle = "Local Moran's I value") +
  mapTheme() +
  theme(plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
        plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
        plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
        axis.line = element_blank(),
        legend.title = element_text(size = 10, family = "sans"),
        legend.text = element_text(size = 9, family = "sans"))

p_cut <- fishnet_pop_cps_morans %>%
  mutate(pval_cut = ifelse(pvalue > 0.05, "Not\nSignificant", "Significant"))

plot_p <- lr_base_map + #ggplot() + #ggmap(cps_base_map) +
  geom_sf(data = ll(p_cut), aes(fill = pval_cut),
          color = NA, inherit.aes = FALSE, alpha = 0.8) +
  scale_fill_viridis_d(na.value=NA, name = "p-value", option = "D") +
  labs(title = "Panel 3",
       subtitle = "Stastically significant\nmaltreatment clusters",
       caption = "Figure 5.5") +
  mapTheme() +
  theme(plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
        plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
        plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
        axis.line = element_blank(),
        legend.title = element_text(size = 10, family = "sans"),
        legend.text = element_text(size = 9, family = "sans"))

MORANS_I_P_plot <- cowplot::plot_grid(plot_cps, plot_Ii, plot_p, ncol =1, align = "hv", axis = "lrbt")
#cowplot::plot_grid(plot_cps, plot_Ii, plot_p,rel_widths = c(0.9,0.9,0.9),ncol = 1, align = "v")

# MORANS_I_P_plot
```

### Aggregate features 

```{r reload_objects-A, echo = F}
load("RData/source_file_objects.RData")

# names(var_list)

var_list <- var_list %>% discard((names(var_list)=="LR_BG_Tracts_ACS_DataJoined"))
var_list <- var_list %>% discard((names(var_list)=="LR_Tracts_Working51"))
var_list <- var_list %>% discard((names(var_list)=="CM_LR_Matched_Centerline_3857"))
var_list <- var_list %>% discard((names(var_list)=="2015_Crime_Part1"))

# names(var_list)
```


```{r start_parallel_backend-A, echo=TRUE, eval = FALSE}
cl <- makePSOCKcluster(3)
registerDoParallel(cl)
```

```{r aggregate_count_features-A, echo=TRUE, eval = FALSE}
source('C:/Users/jd033/Box/Child Maltreatment/R-codes/FUNCTIONS_VAPAP_LR.R')
agg_results <- Aggregate_points_Features(var_list, net_littlerock)
```

```{r euclidean_distance_features-A, echo=TRUE, eval = FALSE}
ED_results <- Euclidean_point_features(var_list, 
                                       lr_rast_SP,
                                       lr_tract_diss, 
                                       net_littlerock)
```



```{r nearest_neighbor_features-A, echo=TRUE, eval = FALSE}
NN_results <- NN_point_features(var_list, net_littlerock, k_nearest_neighbors)
```

```{r stop_parallel_backend-A, echo=TRUE, eval = FALSE}
stopCluster(cl)
```

### Aggregating all features, creating correlation plots and fitting three different models 

```{r remaining_code, echo = T, eval = F}
sf1_tract <- acs %>% dplyr::select(-Incident_Count_sum, -TotPopSize, -NLTotPop)

sf1_tract <- sf1_tract %>%
  mutate(acre = as.numeric(st_area(acs)*2.29568e-5))

vars_sf1_desc <- sf1_tract %>% st_drop_geometry() %>% dplyr::select(starts_with("P"))%>% names()

net_blocks_intersect <- st_intersection(sf1_tract, net_littlerock) 

# group by cell and calc block stats.
net_blocks_intersect2 <- net_blocks_intersect %>%
  mutate(intersect_area_acres = as.numeric(st_area(net_blocks_intersect)*2.29568e-5)) %>%
  group_by(net_id) %>%
  mutate(cnt = n(),
         pcnt_of_block = intersect_area_acres/acre) %>%
  # intersect_pop = value * pcnt_of_block) %>%
  arrange(net_id) %>%
  mutate_at(vars(matches("^P|^T")), funs(.* pcnt_of_block))

### summarise intersect pops to each net cell and create pop rates for some

fishnet_sf1 <- net_blocks_intersect2 %>% # xcc
  group_by(net_id) %>%
  summarise_at(vars(matches("^P|^H")), funs(sum)) %>%
  dplyr::select(-pcnt_of_block) 

## cast data frame to list of variables
sf1_results <- fishnet_sf1 %>%
  gather(variable, value, -net_id, -geometry) %>%
  mutate(feature_name = paste0("SF1_",variable)) %>%
  group_by(variable) %>%
  nest() %>%
  pull(data)
names(sf1_results) <- paste0("SF1_",setdiff(colnames(fishnet_sf1), c("net_id","geometry")))

## 

fishnet_pop_cps_net <- fishnet_pop_cps %>%
  dplyr::select(net_id, net_pop, rate_CPS_Accepted, net_CPS_Accepted) %>%
  rename(cps_rate = rate_CPS_Accepted,
         cps_net  = net_CPS_Accepted)

## NN features combine 

features <- data.frame(net_id = NN_results[[1]]$net_id, stringsAsFactors = FALSE)
for(i in  seq_along(NN_results)){
  feat_i <- NN_results[[i]] %>%
    st_drop_geometry() %>%
    dplyr::select(net_id, feature_name, value) %>%
    spread(feature_name, value)
  features <- left_join(features, feat_i, by = "net_id")
}
# join features to our target of cps_rate
NN_features <- features %>%
  left_join(., st_drop_geometry(fishnet_pop_cps_net), by = "net_id") 

## 

features <- data.frame(net_id = ED_results[[1]][[1]]$net_id, stringsAsFactors = FALSE)
for(i in  seq_along(ED_results[[1]])){
  feat_i <- ED_results[[1]][[i]] %>%
    st_drop_geometry() %>%
    dplyr::select(net_id, feature_name, value = mean_dist ) %>% ### mean_dist  !!!
    spread(feature_name, value)
  features <- left_join(features, feat_i, by = "net_id")
}
# join features to our target of cps_rate
ED_features <- features %>%
  left_join(., st_drop_geometry(fishnet_pop_cps_net), by = "net_id")

## agg_feature_combine 

features <- data.frame(net_id = agg_results[[1]]$net_id, stringsAsFactors = FALSE)
for(i in  seq_along(ED_results[[1]])){
  feat_i <- agg_results[[i]] %>%
    st_drop_geometry() %>%
    dplyr::select(net_id, feature_name, value) %>%
    spread(feature_name, value)
  features <- left_join(features, feat_i, by = "net_id")
}
# join features to our target of cps_rate
agg_features <- features %>%
  left_join(., st_drop_geometry(fishnet_pop_cps_net), by = "net_id")

## sf1-features-combine 

features <- data.frame(net_id = sf1_results[[1]]$net_id, stringsAsFactors = FALSE)
for(i in  seq_along(sf1_results)){
  feat_i <- sf1_results[[i]] %>%
    st_drop_geometry() %>%
    dplyr::select(net_id, feature_name, value) %>%
    spread(feature_name, value)
  features <- left_join(features, feat_i, by = "net_id")
}
# join features to our target of cps_rate
sf1_features <- features %>%
  left_join(., st_drop_geometry(fishnet_pop_cps_net), by = "net_id")

## corr feature remove NA

cor_NN_features <- NN_features %>%
  mutate_all(funs(replace(., is.na(.), 0))) %>%
  dplyr::select(-net_id)

cor_agg_features <- agg_features %>%
  mutate_all(funs(replace(., is.na(.), 0))) %>%
  dplyr::select(-net_id)

cor_ED_features <- ED_features %>%
  mutate(cps_rate = ifelse(is.na(cps_rate),0,cps_rate),
         net_pop = ifelse(is.na(net_pop),0,net_pop)) %>%
  na.omit() %>%
  dplyr::select(-net_id)

cor_sf1_features <- sf1_features %>%
  mutate(cps_rate = ifelse(is.na(cps_rate),0,cps_rate),
         net_pop = ifelse(is.na(net_pop),0,net_pop)) %>%
  na.omit() %>%
  dplyr::select(-net_id)

## combine all features 

ALL_FEATURES <- full_join(NN_features, agg_features, by = "net_id") %>%
  full_join(.,ED_features, by = "net_id") %>%
  full_join(.,sf1_features, by = "net_id")
all.equal(ALL_FEATURES$cps_rate.x, ALL_FEATURES$cps_rate.y, 
          ALL_FEATURES$cps_rate.x.x, ALL_FEATURES$cps_rate.y.y)

NN_CPS_Accepted <- ALL_FEATURES$NN_CPS_Accepted

ALL_FEATURES <- ALL_FEATURES %>%
  dplyr::select(-cps_rate.y, -cps_rate.x.x, -cps_rate.y.y, 
                -cps_net.y, -cps_net.x.x, -cps_net.y.y,
                -net_pop.y, -net_pop.x.x, -net_pop.y.y) %>%
  dplyr::select(-contains("_CPS_")) %>%
  dplyr::rename(cps_net  = cps_net.x,
                cps_rate = cps_rate.x,
                net_pop  = net_pop.x) %>%
  mutate_all(funs(replace(., is.na(.), 0)))  %>%
  dplyr::rename_all(funs(make.names(.)))
## add NN_CPS_Accepted back in to ALL_FEATURES
ALL_FEATURES$NN_CPS_Accepted <- NN_CPS_Accepted


## Corr all plot 

cps_cor_ALL <- cor(ALL_FEATURES)
All_cors <- cps_cor_ALL[,"cps_net"]

p.mat_ALL <- cor.mtest(ALL_FEATURES)$p
p.mat_ALL <- p.mat_ALL[,which(colnames(cps_cor_ALL)=="cps_net")]

cor_ALL_plot <- data.frame(feature = names(All_cors), 
                           cor = as.numeric(All_cors),
                           p_value   = p.mat_ALL) %>%
  filter(!(feature %in% c("cps_rate","cps_net","net_pop","net_cps","net_id"))) %>%
  filter(!(feature %in% grep("CPS", names(All_cors),value=T))) %>%
  arrange(desc(cor)) %>% 
  mutate(p_value = ifelse(p_value >= 0.05, "Not Significant", "Significant"))

cor_ALL_plot$feature <- factor(cor_ALL_plot$feature,
                               levels=cor_ALL_plot[order(cor_ALL_plot$cor,
                                                         decreasing=F),]$feature)
## corr line positive feature 

CORR_LINE_POSITIVE_FEATURE_plot <- ggplot(dplyr::filter(cor_ALL_plot,cor >= 0), 
                                          aes(x = feature, y = cor, color = factor(p_value))) +
  geom_segment(aes(x = feature, y = 0, xend = feature, yend = cor), color = "grey50") +
  geom_point() +
  coord_flip() +
  scale_color_discrete(name = "p-value") +
  theme_bw()+
  theme(axis.text.y = element_text(size=8))

CORR_LINE_POSITIVE_FEATURE_plot

## corr line negative feature plot 

CORR_LINE_NEGATIVE_FEATURE_plot <- ggplot(dplyr::filter(cor_ALL_plot,cor <= 0), 
                                          aes(x = feature, y = cor, color = factor(p_value))) +
  geom_segment(aes(x = feature, y = 0, xend = feature, yend = cor), color = "grey50") +
  geom_point() +
  coord_flip() +
  scale_color_discrete(name = "p-value") +
  theme_bw()+
  theme(axis.text.y = element_text(size=6))

CORR_LINE_NEGATIVE_FEATURE_plot

## features corr strong 

features_cor <- cor_ALL_plot %>%
  mutate(feature = as.character(feature)) %>%
  arrange(desc(cor)) %>%
  pull(feature)
top_n <- head(features_cor,10)
bottom_n <- tail(features_cor,10)

features_strong_cor <- ALL_FEATURES %>%
  dplyr::select(top_n, bottom_n, cps_net, cps_rate, net_pop, net_id) %>%
  base::identity()


### Now this line has to be modified to meet our needs 
features_protective_all <- ALL_FEATURES %>%
  dplyr::select(contains("Banks"),
                contains("GrocerySuperMarket"),
                contains("HighSchoolsPublic"),
                contains("HotelMotel"),
                contains("ChildCareServices"),
                contains("ChildYouthServices"),
                contains("CivilSocialOrgs"),
                         contains("Hospitals"),
                         contains("NeighborhoodResourceCenters"),
                         contains("PoliceFacilities"),
                         contains("ReligiousOrgs"),
                NN_CPS_Accepted,
                cps_net, cps_rate, net_pop, net_id)

features_strong_protective_names <- cor_ALL_plot %>% 
  filter(feature %in% names(features_protective_all)) %>%
  mutate(prefix = str_extract(feature, "^[^_]+(?=_)"),
         suffix = str_extract(feature, "(?<=_)[^_].*"),
         feature = as.character(feature)) %>%
  group_by(suffix) %>%
  slice(which.max(abs(cor)))

features_protective_strong <- features_protective_all %>%
  dplyr::select(features_strong_protective_names$feature,
                NN_CPS_Accepted,
                cps_net, cps_rate, net_pop, net_id) %>%
  base::identity()


## risk features all

features_risk_all <- ALL_FEATURES %>%
  dplyr::select(contains("CRIME_THEFT.OF.PROPERTY.FELONY"),
                contains("CRIME_BURGLARY...RESIDENTIAL"),
                contains("CRIME_TERRORISTIC.ACT"),
                contains("NN_CRIME_THEFT.OF.PROPERTY.MISD"),
                contains("NN_CRIME_RAPE"),                                                
                contains("NN_CRIME_BATTERY.2ND.DEGREE" ),                                 
                contains("NN_CRIME_DOMESTIC.BATTERING.2ND.DEGREE"),                       
                contains("NN_CRIME_BREAKING.OR.ENTERING.VEHICLE" ),                       
                contains("NN_CRIME_AGGRAVATED.ROBBERY..INDIVIDUAL." ),                    
                contains("NN_CRIME_ROBBERY..INDIVIDUAL."  ),                              
                contains("NN_CRIME_AGGRAVATED.ASSAULT.ON.AN.FAMILY.OR.HOUSEHOLD.MEMBER" ),
                contains("NN_CRIME_BURGLARY.COMMERCIAL" ),                                
                contains("NN_CRIME_BATTERY.1ST.DEGREE"), 
                contains("BarberAndBeautyShops"),
                contains("BusStops"),
                contains("CheckCashingAndPawn"),
                contains("FastFoodAndBeverage"),
                contains("GasStationAndConvMart"),
                contains("HotelMotel"),
                contains("LiquorStores"),
                contains("MajorDeptRetailDiscount"),
                contains("MixedDrink_BarRestClub"),
                contains("Rental_MobileHomes"),
                contains("Rental_SingleToQuad"),
                contains("Rentals_Apts_LessThan100units"),
                contains("Rentals_Apts_Over100units"),
                contains("TattooPiercing"),
                contains("Unsafe_Vacant_BldgsNEW"),
                NN_CPS_Accepted,
                cps_net, cps_rate, net_pop, net_id)

## features_risk_strong

features_risk_strong_names <- cor_ALL_plot %>%
  filter(feature %in% names(features_risk_all)) %>%
  mutate(prefix = str_extract(feature, "^[^_]+(?=_)"),
         suffix = str_extract(feature, "(?<=_)[^_].*"),
         feature = as.character(feature)) %>%
  group_by(suffix) %>%
  slice(which.max(abs(cor)))

features_risk_strong <- features_risk_all %>%
  dplyr::select(features_risk_strong_names$feature,
                NN_CPS_Accepted,
                cps_net, cps_rate, net_pop, net_id) %>%
  base::identity()

# features_census_select

features_census_select <- ALL_FEATURES %>%
  dplyr::select(SF1_Perc_Under18,
                 SF1_Perc_Black, 
                 SF1_Perc_NonWh, 
                 SF1_Perc_Hispa,
                 SF1_Perc_NonMarr_Fam_HH,
                 SF1_Perc_FHH, 
                 SF1_Perc_SingPrnt_HH,
                 SF1_PercLowEdu, 
                 SF1_Perc_RenterOcc,
                 SF1_Perc_PopUnder18inPov,
                 SF1_Perc_PopStrugg,
                 SF1_Perc_NotInsured,
                 SF1_Perc_PublicInsure,
                 SF1_PercHighHH, 
                 SF1_PercCollEd,
                 SF1_Perc_OwnHo,   
                 cps_net, cps_rate, net_pop, net_id)

features_risk_strong_plot <- features_risk_strong %>%
  dplyr::select(-net_id)

CORR_RISK_FEATURES_plot <- feature_corrplot(features_risk_strong_plot, "Correlation of Risk Features")

features_protective_strong_plot <- features_protective_strong %>%
  dplyr::select(-net_id)
CORR_PROTECTIVE_FEATURES_plot <- feature_corrplot(features_protective_strong_plot, "Correlation of Protective Features")

## Line 1096 is Corr-protective-features-plot 
## Line 1560 is feature prep 
## We can safely ignore bunch of plots in between these two chunks 
## feature prep 

target_var <- "cps_net"
features_protective_strong2 <- dplyr::select(features_protective_strong, -cps_rate, -net_pop)
features_risk_strong2 <- dplyr::select(features_risk_strong, -cps_rate, -net_pop)
features_census_select2     <- dplyr::select(features_census_select, -cps_rate, -net_pop)


## model data prep 

full_join(features_risk_strong, features_census_select, by = "net_id") %>%
  full_join(., features_protective_strong, by = "net_id") %>% names()

og_dat <- full_join(features_risk_strong, features_census_select, by = "net_id") %>%
  full_join(., features_protective_strong, by = "net_id") %>% 
  dplyr::select(-net_pop.y, -cps_net.y, -cps_rate.y,
                -net_pop.x, -cps_net.x, -cps_rate.x) 
 

dat    <- og_dat %>% dplyr::select(-cps_rate, -net_pop, -net_id) %>%
  mutate_at(vars(-cps_net), scale_this) %>%
  identity() # line ender (does nothing)

net_hood <- st_join(net_littlerock, lr_tract, largest = TRUE)
all.equal(net_hood$net_id, og_dat$net_id)
og_dat$.block_id <- net_hood$NAME

## tract fixed effects 

hood_matrix <- model.matrix(cps_net~.block_id,og_dat)
hood_model <- lm(sqrt(og_dat$cps_net) ~ hood_matrix)
dat$hood_fixed <- predict(hood_model, type = "response")^2
og_dat$hood_fixed <- predict(hood_model, type = "response")^2


## create cv fold_tibble 

n_folds = 5

target_var <- "cps_net"

all_hoods <- length(unique(net_hood$name))
n_folds = ifelse(n_folds == "LOOCV", all_hoods, n_folds)
folds_index <- groupdata2::fold(og_dat, k = n_folds, id_col = '.block_id')$.folds

cv_tbl <- tibble(folds = seq_len(n_folds),
                 train = NA, train_y = NA, train_index = NA, train_net_id = NA,
                 test  = NA, test_y  = NA, test_index  = NA, test_net_id  = NA)

for(k in seq_len(n_folds)){
  fold_i  <- which(folds_index == k)
  cv_tbl[k,]$train         <- list(dat[-fold_i,])
  cv_tbl[k,]$test          <- list(dat[ fold_i,])
  cv_tbl[k,]$train_y       <- list(og_dat[-fold_i,target_var])
  cv_tbl[k,]$test_y        <- list(og_dat[ fold_i,target_var])
  cv_tbl[k,]$train_index   <- list(setdiff(seq(1:nrow(dat)),fold_i))
  cv_tbl[k,]$test_index    <- list(fold_i)
  cv_tbl[k,]$train_net_id  <- list(og_dat[-fold_i,"net_id"])
  cv_tbl[k,]$test_net_id   <- list(og_dat[ fold_i,"net_id"])
}

cv_sf <- left_join(og_dat, net_littlerock, by = "net_id") %>%
  st_as_sf() %>%
  dplyr::select(.block_id)
NEIGHBORHOOD_FOLDS_plot <- plot(cv_sf)

## Poisson regression 

po_cv_tbl <- cv_tbl %>%
  mutate(fit   = map(train, glm_fit, 
                     formula =  paste("cps_net ~ ."), 
                     family = "poisson"),
         pred  = map2(fit, test, lm_predict, sqrt = FALSE),
         mdl_nam = "GLM - Poisson") %>% 
  score_model()
cat("Test Set MAE:",mean(po_cv_tbl$MAE),"\n")
cat("Test Set logdev:",mean(po_cv_tbl$logdev, na.rm=TRUE),"\n")

## Poisson Regression fit plot 

POISSON_REGRESSION_FIT_plot <- plot_fold_pred(po_cv_tbl$pred, po_cv_tbl$test_y, type = "fit")

POISSON_REGRESSION_FIT_plot

## Random Forest 

rf_cv_tbl <- cv_tbl %>%
  mutate(fit   = map(train, rf_fit, formula = "cps_net ~ .", mtry_add = 2, importance = "impurity"),
         pred  = map2(fit, test, lm_predict),
         mdl_nam = "Random Forest") %>% 
  score_model()
cat("Test Set MAE:",mean(rf_cv_tbl$MAE),"\n")
cat("Test Set logdev:",mean(rf_cv_tbl$logdev, na.rm=TRUE),"\n")


## Random Forest Var Imp Plot 

varimp_dat <- data.frame(importance = rf_cv_tbl$fit[[1]]$variable.importance) %>% 
  rownames_to_column("variable")

RF_VARIMP_PLOT <- ggplot(varimp_dat, aes(x=reorder(variable,importance), y=importance, fill=importance))+ 
  geom_bar(stat="identity", position="dodge")+ coord_flip()+
  labs(y = "Variable Importance",
       x = " ", 
       title = "Feature importance",
       subtitle = "Random Forest sub-model",
       caption = "Figure 6.4") +
  guides(fill=F)+
  scale_fill_viridis_c() +
  plotTheme()+
  theme(axis.text.y = element_text(size = 6))

RF_VARIMP_PLOT

ggsave(file = "RF-Var-Imp-Plot.png",RF_VARIMP_PLOT, height = 9, width = 7)

RANDOM_FOREST_FIT_plot <- plot_fold_pred(rf_cv_tbl$pred, rf_cv_tbl$test_y, type = "fit")

RANDOM_FOREST_FIT_plot

## Spatial Error Regression

spat_durbin <- errorsarlm(sqrt(cps_net) ~ ., data = dat, listw, etype ="emixed")
spat_durbin_tbl <- tibble(
  fit   = list(spat_durbin),
  pred  = map(fit, sar_pred),
  test_y= list(dat$cps_net),
  test_net_id = list(og_dat$net_id),
  mdl_nam = "Spatial Durbin - sqrt") %>% 
  score_model()
cat("Test Set MAE:",mean(spat_durbin_tbl$MAE),"\n")
cat("Test Set logdev:",mean(spat_durbin_tbl$logdev, na.rm=TRUE),"\n")

SPATIAL_ERROR_FIT_plot <- plot_fold_pred(spat_durbin_tbl$pred, dat$cps_net, type = "fit")

POISSON_REGRESSION_FIT_plot+RANDOM_FOREST_FIT_plot+SPATIAL_ERROR_FIT_plot


## Gather oof prediction 

po_pred_dat <- po_cv_tbl %>%
  unnest(pred) %>%
  mutate(test_y = po_cv_tbl %>% unnest(test_y) %>% pull(test_y),
         test_net_id = po_cv_tbl %>% unnest(test_net_id) %>% pull(test_net_id))

po_pred_geoplot <- model_pred_geoplot(po_pred_dat$pred,
                                      po_pred_dat$test_y,
                                      po_pred_dat$test_net_id,
                                      net_littlerock, cps_base_map, "po")

rf_pred_dat <- rf_cv_tbl %>%
  unnest(pred) %>%
  mutate(test_y = rf_cv_tbl %>% unnest(test_y) %>% pull(test_y),
         test_net_id = rf_cv_tbl %>% unnest(test_net_id) %>% pull(test_net_id))

rf_pred_geoplot <- model_pred_geoplot(rf_pred_dat$pred,
                                      rf_pred_dat$test_y,
                                      rf_pred_dat$test_net_id,
                                      net_littlerock, cps_base_map,
                                      "Rand
                                      om Forest")
### One special 
if(T){
  pred_dat <- data.frame(pred = rf_pred_dat$pred,
                         obs  = rf_pred_dat$test_y,
                         net_id = rf_pred_dat$test_net_id)
  
  MAE_geoplot <- net_littlerock %>%
    left_join(., pred_dat, by = "net_id") %>% 
    mutate(MAE = round(abs(pred - obs),2),
           feature_name = paste0("RF"," ", "MAE")) %>%
    make_cuts(., "MAE")
  
  MAE_geoplot %>%  ggplot(aes(fill = MAE)) + 
    geom_sf(color = NA) + 
    scale_fill_viridis_d() + 
    labs(title = "MAE")
}


###
sarlm_pred_dat <- spat_durbin_tbl %>%
  unnest(pred) %>%
  mutate(test_y = spat_durbin_tbl %>% unnest(test_y) %>% pull(test_y),
         test_net_id = spat_durbin_tbl %>% unnest(test_net_id) %>% pull(test_net_id))

sarlm_pred_geoplot <- model_pred_geoplot(sarlm_pred_dat$pred,
                                         sarlm_pred_dat$test_y,
                                         sarlm_pred_dat$test_net_id,
                                         net_littlerock, cps_base_map,
                                         "SARLM")


cps_preds <- og_dat %>% 
  dplyr::select(net_id, cps_net) %>% 
  left_join(., dplyr::select(po_pred_dat,
                             net_id = test_net_id,
                             pred_lm = pred), by = "net_id") %>%
  left_join(., dplyr::select(rf_pred_dat, 
                             net_id = test_net_id,
                             pred_rf = pred), by = "net_id") %>% 
  left_join(., dplyr::select(sarlm_pred_dat, 
                             net_id = test_net_id,
                             pred_sarlm = pred), by = "net_id") %>% 
  mutate_if(is.double, round, 2)


## Meta model stacking 

if(all.equal(cps_preds$net_id, net_hood$net_id)){
  cat("Predictions and spatial data are in same order, GOOD to go!", "\n")
} else {
  cat("There is a PROBLEM with order of predictions and spatial data; Likely Errors!","\n")
}

cps_preds_cv_dat <- dplyr::select(cps_preds, -net_id)
ens_cv_tbl <- tibble(folds = seq_len(n_folds),
                     train = NA, train_y = NA, train_index = NA, train_net_id = NA,
                     test  = NA, test_y  = NA, test_index  = NA, test_net_id  = NA)
for(k in seq_len(n_folds)){
  fold_i  <- which(folds_index == k)
  ens_cv_tbl[k,]$train         <- list(cps_preds_cv_dat[-fold_i,])
  ens_cv_tbl[k,]$test          <- list(cps_preds_cv_dat[ fold_i,])
  ens_cv_tbl[k,]$train_y       <- list(cps_preds_cv_dat[-fold_i,target_var])
  ens_cv_tbl[k,]$test_y        <- list(cps_preds_cv_dat[ fold_i,target_var])
  ens_cv_tbl[k,]$train_index   <- list(setdiff(seq(1:nrow(cps_preds_cv_dat)),fold_i))
  ens_cv_tbl[k,]$test_index    <- list(fold_i)
  ens_cv_tbl[k,]$train_net_id  <- list(cps_preds[-fold_i,"net_id"])
  ens_cv_tbl[k,]$test_net_id   <- list(cps_preds[ fold_i,"net_id"])
}

ens_cv_tbl <- ens_cv_tbl %>%
  mutate(fit   = map(train, rf_fit, formula = "cps_net ~ pred_rf + pred_sarlm"),
         pred  = map2(fit, test, lm_predict),
         # pred  = map(pred, round),
         mdl_nam = "Meta-Model") %>% 
  score_model()

cat("Test Set MAE:",mean(ens_cv_tbl$MAE),"\n")
cat("Test Set logdev:",mean(ens_cv_tbl$logdev),"\n")

## Meta model fit plot 

META_MODEL_FIT_plot <- plot_fold_pred(ens_cv_tbl$pred, ens_cv_tbl$test_y, type = "fit") +
  labs(x = "Observed Maltreatment Counts",
       y = "Predicted Maltreatment Counts",
       title = "Predicted vs. observed maltreatment counts",
       caption = "Figure 1.7") +
  plotTheme() +
  theme(panel.border = element_blank())

## join meta moodel predictions

ens_pred_dat <- ens_cv_tbl %>% 
  unnest(pred) %>% 
  mutate(test_y = ens_cv_tbl %>% unnest(test_y) %>% pull(test_y),
         test_net_id = ens_cv_tbl %>% unnest(test_net_id) %>% pull(test_net_id)) 

ens_pred_geoplot <- model_pred_geoplot(ens_pred_dat$pred, 
                                       ens_pred_dat$test_y, 
                                       ens_pred_dat$test_net_id,
                                       net_littlerock, cps_base_map, 
                                       "Meta-Model")
cps_preds2 <- cps_preds %>% 
  left_join(., dplyr::select(ens_pred_dat, 
                             net_id = test_net_id,
                             pred_ens = pred) %>% 
              mutate(pred_ens = round(pred_ens,2)), by = "net_id") 

## PREDICTION_MAP_plots

POISSON_MODEL_PREDICTION_MAP_plot <- cowplot::plot_grid(po_pred_geoplot[[2]] + 
                                                          labs(title = "Poisson Regression",
                                                               subtitle = "Predicted Maltreatment Count"), 
                                                        po_pred_geoplot[[1]] + 
                                                          labs(subtitle = "MAE") +
                                                          scale_fill_viridis_d(name = "MAE"), 
                                                        align = "h")

POISSON_MODEL_PREDICTION_MAP_plot

RF_MODEL_PREDICTION_MAP_plot <- cowplot::plot_grid(rf_pred_geoplot[[2]] + 
                                                     labs(title = "Random Forest",
                                                          subtitle = "Predicted Maltreatment Count"),
                                                   rf_pred_geoplot[[1]] + 
                                                     labs(subtitle = "MAE") +
                                                     scale_fill_viridis_d(name = "MAE"), 
                                                   align = "h")

RF_MODEL_PREDICTION_MAP_plot


SARLM_MODEL_PREDICTION_MAP_plot <- cowplot::plot_grid(sarlm_pred_geoplot[[2]] + 
                                                        labs(title = "Spatial Durbin Model",
                                                             subtitle = "Predicted Maltreatment Count") +
                                                        mapTheme() + 
                                                        theme(panel.border = element_blank()), 
                                                      sarlm_pred_geoplot[[1]] + 
                                                        labs(subtitle = "MAE") +
                                                        scale_fill_viridis_d(name = "MAE") +
                                                        mapTheme() + 
                                                        theme(panel.border = element_blank()), 
                                                      align = "h")

META_MODEL_PREDICTION_MAP_plot <- cowplot::plot_grid(ens_pred_geoplot[[2]] + 
                                                       labs(title = "Meta-Model",
                                                            subtitle = "Predicted Maltreatment Count",
                                                            caption = "Figure 6.2") +
                                                       mapTheme() + 
                                                       theme(panel.border = element_blank()), 
                                                     ens_pred_geoplot[[1]] + 
                                                       labs(subtitle = "MAE") +
                                                       scale_fill_viridis_d(name = "MAE") +
                                                       mapTheme() + 
                                                       theme(panel.border = element_blank()), 
                                                     align = "h")

### r model_error_by_decile
models <- bind_rows(rf_cv_tbl, spat_durbin_tbl, ens_cv_tbl, po_cv_tbl)

CV_preds_long <- models %>%
  group_by(mdl_nam) %>%
  unnest(pred, test_y) 

## map over all quantiles to get error metrics
quantile_errors <- CV_preds_long %>%
  nest(-mdl_nam) %>%
  mutate(q      = list(seq(0,1,0.01)),
         pred   = map(data, "pred"),
         test_y = map(data, "test_y")) %>%
  dplyr::select(-data) %>%
  unnest(q, .preserve = c(pred, test_y)) %>%
  filter(q != 0) %>% 
  mutate(q_dat  = pmap(list(pred, test_y, q), quantile_error),
         q_pred = map(q_dat, "pred"),
         q_obs  = map(q_dat, "obs"),
         q_RMSE = map2_dbl(q_pred, q_obs, rmse),
         q_MAE  = map2_dbl(q_pred, q_obs, mae),
         q_logdev  = map2_dbl(q_pred, q_obs, logdev_p),
         y_max  = quantile(seq(0,max(dat$cps_net)), q),
         q_cnt  = nrow(og_dat) - map_int(q_dat, nrow))

q_error_plotdat <- quantile_errors %>%
  dplyr::select(mdl_nam, q, q_RMSE, q_MAE, q_logdev)
q_cnt_plotdat <- quantile_errors %>% 
  dplyr::select(mdl_nam, q, y_max, q_cnt) %>% 
  filter(q != 0) %>%
  mutate(q_pcnt = (q_cnt / nrow(og_dat)))
q_error_mean <- q_error_plotdat %>%
  group_by(mdl_nam) %>%
  summarise(mean_RMSE = mean(q_RMSE, na.rm = TRUE),
            mean_MAE  = mean(q_MAE, na.rm = TRUE),
            mean_logdev  = mean(q_logdev, na.rm = TRUE)) %>%
  arrange(desc(mean_logdev))
print(q_error_mean)


## Appendix 4e - Model Error Table 


# Helper function for quantile error
quantile_error <- function(pred,obs,quant){
  preds <- data.frame(pred = pred, obs = obs) %>%
    filter(quantile(seq(0,max(obs)), quant)>obs)
  return(preds)
}
# Join/bind model prediction tables
models <- bind_rows(rf_cv_tbl, spat_durbin_tbl, ens_cv_tbl, po_cv_tbl)
# Unnest predictions by model
CV_preds_long <- models %>%
  group_by(mdl_nam) %>%
  unnest(pred, test_y) 
## Map over all quantiles to get error metrics
quantile_errors <- CV_preds_long %>%
  nest(-mdl_nam) %>%
  mutate(q      = list(seq(0,1,0.01)),
         pred   = map(data, "pred"),
         test_y = map(data, "test_y")) %>%
  dplyr::select(-data) %>%
  unnest(q, .preserve = c(pred, test_y)) %>%
  filter(q != 0) %>% 
  mutate(q_dat  = pmap(list(pred, test_y, q), quantile_error),
         q_pred = map(q_dat, "pred"),
         q_obs  = map(q_dat, "obs"),
         q_RMSE = map2_dbl(q_pred, q_obs, rmse),
         q_MAE  = map2_dbl(q_pred, q_obs, mae),
         q_logdev  = map2_dbl(q_pred, q_obs, logdev_p),
         y_max  = quantile(seq(0,max(dat$cps_net)), q),
         q_cnt  = nrow(og_dat) - map_int(q_dat, nrow))

# Map over all predictions grouped by model to calculate mean and sd for error metrics
model_results <- models %>%
  dplyr::select("Model Name" = mdl_nam, R2, RMSE, MAE, logdev) %>%
  group_by(`Model Name`) %>%
  arrange(`Model Name`) %>%
  summarise(R2_mean      = mean(R2, na.rm=TRUE),
            R2_sd        = sd(R2, na.rm=TRUE),
            MAE_mean     = mean(MAE, na.rm=TRUE),
            MAE_sd       = sd(MAE, na.rm=TRUE),
            RMSE_mean    = mean(RMSE, na.rm=TRUE),
            RMSE_sd      = sd(RMSE, na.rm=TRUE),
            logdev_mean  = mean(logdev, na.rm=TRUE),
            logdev_sd    = sd(logdev, na.rm=TRUE)) 
Model_Error_Results_table <- model_results %>%
  kable(., format = "html", digits = 3) %>%
  kable_styling()

```

```{r addition_0721, echo = T, eval = F}
## Line 1929 of Richmond PAP Report R markdown 

meta_log_mean <- model_results[which(model_results$`Model Name` == "Meta-Model"),"logdev_mean",drop=TRUE]
meta_log_sd <- model_results[which(model_results$`Model Name` == "Meta-Model"),"logdev_sd",drop=TRUE]
meta_log_error <- qnorm(0.975)*meta_log_sd/sqrt(nrow(ens_cv_tbl))
meta_log_error_lower <- round(meta_log_mean - meta_log_error,3)
meta_log_error_upper <- round(meta_log_mean + meta_log_error,3)

meta_MAE_mean <- model_results[which(model_results$`Model Name` == "Meta-Model"),"MAE_mean",drop=TRUE]
meta_MAE_sd <- model_results[which(model_results$`Model Name` == "Meta-Model"),"MAE_sd",drop=TRUE]
meta_MAE_error <- qnorm(0.975)*meta_MAE_sd/sqrt(nrow(ens_cv_tbl))
meta_MAE_error_lower <- round(meta_MAE_mean - meta_MAE_error,3)
meta_MAE_error_upper <- round(meta_MAE_mean + meta_MAE_error,3)


## chunk aggregate_model_errors_to_neighborhood

error_geoplot <-  net_littlerock %>%
  left_join(., ens_pred_dat, by = c("net_id" = "test_net_id"),
            feature_name = paste0("Meta-Model", "dev")) %>%
  score_model() %>%
  mutate(dev_p_inv = 1 - logdev) %>% 
  make_cuts(., "logdev", cuts = "breaks", n_breaks = 5)

# error metrics to points
error_points <- st_centroid(error_geoplot) %>%
  dplyr::select(logdev, MAE, test_y) ##add net_id

# aggreate mean errors to neighborhoods
neighborhood_metric_logdev <- error_points %>%
  aggregate(., lr_tract, mean) %>%
  dplyr::select(logdev) %>% 
  make_cuts(., "logdev")  ## lr_tract replaces nbr

neighborhood_metric_MAE<- error_points %>%
  aggregate(., lr_tract, mean) %>%
  dplyr::select(MAE) %>% 
  mutate(MAE = round(MAE,2)) %>% 
  make_cuts(., "MAE")

## model error by decile 

models <- bind_rows(rf_cv_tbl, spat_durbin_tbl, ens_cv_tbl, po_cv_tbl)

CV_preds_long <- models %>%
  group_by(mdl_nam) %>%
  unnest(pred, test_y) 

## map over all quantiles to get error metrics
quantile_errors <- CV_preds_long %>%
  nest(-mdl_nam) %>%
  mutate(q      = list(seq(0,1,0.01)),
         pred   = map(data, "pred"),
         test_y = map(data, "test_y")) %>%
  dplyr::select(-data) %>%
  unnest(q, .preserve = c(pred, test_y)) %>%
  filter(q != 0) %>% 
  mutate(q_dat  = pmap(list(pred, test_y, q), quantile_error),
         q_pred = map(q_dat, "pred"),
         q_obs  = map(q_dat, "obs"),
         q_RMSE = map2_dbl(q_pred, q_obs, rmse),
         q_MAE  = map2_dbl(q_pred, q_obs, mae),
         q_logdev  = map2_dbl(q_pred, q_obs, logdev_p),
         y_max  = quantile(seq(0,max(dat$cps_net)), q),
         q_cnt  = nrow(og_dat) - map_int(q_dat, nrow))

q_error_plotdat <- quantile_errors %>%
  dplyr::select(mdl_nam, q, q_RMSE, q_MAE, q_logdev)
q_cnt_plotdat <- quantile_errors %>% 
  dplyr::select(mdl_nam, q, y_max, q_cnt) %>% 
  filter(q != 0) %>%
  mutate(q_pcnt = (q_cnt / nrow(og_dat)))
q_error_mean <- q_error_plotdat %>%
  group_by(mdl_nam) %>%
  summarise(mean_RMSE = mean(q_RMSE, na.rm = TRUE),
            mean_MAE  = mean(q_MAE, na.rm = TRUE),
            mean_logdev  = mean(q_logdev, na.rm = TRUE)) %>%
  arrange(desc(mean_logdev))
print(q_error_mean)

### Error decile plots 

LOGDEV_MODEL_ERROR_BY_DECILE_plot <- ggplot(data = q_error_plotdat, aes(x=q, y=q_logdev, group = mdl_nam, color = factor(mdl_nam))) +
  geom_line(size = 1) +
  scale_color_viridis_d(name = "Model") +
  scale_y_continuous(limits=c(0,1)) +
  labs(y = "Logarithmic Score",
       caption = "Figure 6.2 - Goodness of fit by decile") +
  plotTheme() +
  theme(legend.position = "right")

MAE_MODEL_ERROR_BY_DECILE_plot <- ggplot(data = q_error_plotdat, aes(x=q, y=q_MAE, group = mdl_nam, color = factor(mdl_nam))) +
  geom_line(size = 1) +
  scale_color_viridis_d(name = "Model") +
  labs(y = "MAE") +
  plotTheme()  +
  theme(legend.position = "right")

COUNT_BY_DECILE_plot <- ggplot(data = q_cnt_plotdat, 
                               aes(x=q, y=q_cnt, group = mdl_nam, color = factor(mdl_nam))) +
  geom_line(size = 1) +
  scale_x_continuous(breaks=seq(0,1,0.1), labels = seq(0,1,0.1)) +
  scale_color_viridis_d(name = "Model") +
  labs(y = "Number of Predictions in Each Decile",
       x = "Decile") +
  plotTheme()  +
  theme(legend.position = "right")


legend <- get_legend(LOGDEV_MODEL_ERROR_BY_DECILE_plot + plotTheme() + theme(legend.position = "right"))

### Model_Error_Results_table

model_results <- models %>%
  dplyr::select("Model Name" = mdl_nam, R2, RMSE, MAE, logdev) %>%
  group_by(`Model Name`) %>%
  arrange(`Model Name`) %>%
  summarise(R2_mean      = mean(R2, na.rm=TRUE),
            R2_sd        = sd(R2, na.rm=TRUE),
            MAE_mean     = mean(MAE, na.rm=TRUE),
            MAE_sd       = sd(MAE, na.rm=TRUE),
            RMSE_mean    = mean(RMSE, na.rm=TRUE),
            RMSE_sd      = sd(RMSE, na.rm=TRUE),
            logdev_mean  = mean(logdev, na.rm=TRUE),
            logdev_sd    = sd(logdev, na.rm=TRUE)) 
Model_Error_Results_table <- model_results %>%
  kable(., format = "html", digits = 3) %>%
  kable_styling()

meta_log_mean <- model_results[which(model_results$`Model Name` == "Meta-Model"),"logdev_mean",drop=TRUE]
meta_log_sd <- model_results[which(model_results$`Model Name` == "Meta-Model"),"logdev_sd",drop=TRUE]
meta_log_error <- qnorm(0.975)*meta_log_sd/sqrt(nrow(ens_cv_tbl))
meta_log_error_lower <- round(meta_log_mean - meta_log_error,3)
meta_log_error_upper <- round(meta_log_mean + meta_log_error,3)

meta_MAE_mean <- model_results[which(model_results$`Model Name` == "Meta-Model"),"MAE_mean",drop=TRUE]
meta_MAE_sd <- model_results[which(model_results$`Model Name` == "Meta-Model"),"MAE_sd",drop=TRUE]
meta_MAE_error <- qnorm(0.975)*meta_MAE_sd/sqrt(nrow(ens_cv_tbl))
meta_MAE_error_lower <- round(meta_MAE_mean - meta_MAE_error,3)
meta_MAE_error_upper <- round(meta_MAE_mean + meta_MAE_error,3)

## Line 1944 : change nbr to lr_tract
## Chunk aggregate_model_errors_to_neighborhood

error_geoplot <-  net_littlerock %>%
  left_join(., ens_pred_dat, by = c("net_id" = "test_net_id"),
            feature_name = paste0("Meta-Model", "dev")) %>%
  score_model() %>%
  mutate(dev_p_inv = 1 - logdev) %>% 
  make_cuts(., "logdev", cuts = "breaks", n_breaks = 5)

# error metrics to points
error_points <- st_centroid(error_geoplot) %>%
  dplyr::select(logdev, MAE, test_y)

# aggreate mean errors to neighborhoods
neighborhood_metric_logdev <- error_points %>%
  aggregate(., lr_tract, mean) %>%
  dplyr::select(logdev) %>% 
  make_cuts(., "logdev")

neighborhood_metric_MAE<- error_points %>%
  aggregate(., lr_tract, mean) %>%
  dplyr::select(MAE) %>% 
  mutate(MAE = round(MAE,2)) %>% 
  make_cuts(., "MAE")

##MODEL_ERROR_BY_NEIGHBORHOOD_plots

LOGDEV_BY_NEIGHBORHOOD_plot <- make_fishnet_dist_plot(neighborhood_metric_logdev, cps_base_map, legend = "right", 
                                                      direction = 1, var_name = "Deviance", 
                                                      title = "Out-of-Fold error by Census Tract") + 
  labs(caption = "Figure 6.3",
       subtitle = "Logarithmic score") +
  mapTheme()

MAE_BY_NEIGHBORHOOD_plot <- make_fishnet_dist_plot(neighborhood_metric_MAE, cps_base_map, legend = "right", 
                                                   direction = 1, var_name = "MAE") +
  labs(subtitle = "MAE") +
  mapTheme()

MAE_BY_NEIGHBORHOOD_plot

## The following lines are inside the main text - not loaded chunks 
## See lines 3540-3547 of Richmond-PAP-Report Rmd

plot_fold_pred(ens_cv_tbl$pred, ens_cv_tbl$test_y, type = "fit") +
  labs(x = "Observed Maltreatment Counts",
       y = "Predicted Maltreatment Counts",
       title = "Predicted vs. observed maltreatment counts",
       caption = "Figure 6.1") +
  plotTheme() +
  theme(panel.border = element_blank())

```

```{r observed_vs_predicted,echo = T, eval = F}
## The following lines are inside the main text - not loaded chunks 
## See lines 3540-3547 of Richmond-PAP-Report Rmd

plot_fold_pred(ens_cv_tbl$pred, ens_cv_tbl$test_y, type = "fit") +
  labs(x = "Observed Maltreatment Counts",
       y = "Predicted Maltreatment Counts",
       title = "Predicted vs. observed maltreatment counts",
       caption = "Figure 6.1") +
  plotTheme() +
  theme(panel.border = element_blank())
```


```{r statistical_area_download, echo = T, eval = F}

## Below we calculate poverty and nonWhite rates by neighborhood by converting tracts to centroids and spatial joining with 
#neighborhoods statistical areas. 

lr_tract_statAreas <- lr_tract %>% mutate(stat_area_id = GEOID)
```

```{r ACS_data_download, echo = T, eval = F}

## We don't have to download acs data using get_acs function (we have this already as shapefiles)

tract10 <- var_list[["LR_BG_Tracts_ACS_DataJoined"]]

tract10 <- tract10 %>% dplyr::select(TotPopSize, Perc_NonWh, Perc_PopSt, 
                                     Perc_NotIn, Perc_PopUn,geometry)
```

```{r ACS_Rates, echo = T, eval = F}
tract10 <- tract10 %>% dplyr::rename( Perc_PopUnder18inPov = Perc_PopUn,
            Perc_PopStrugg = Perc_PopSt,
            Perc_NotInsured = Perc_NotIn,
            TotalPop = TotPopSize) %>% 
            dplyr::mutate(tract_id = dplyr::row_number(),
                          NumberWhites = ifelse(TotalPop > 0, (TotalPop*(1-Perc_NonWh)),0),
                          TotalPoverty = TotalPop*Perc_PopStrugg) 
            

tract10$tract_area <- st_area(tract10)
```

```{r census_statistical_area_spatial_intersection, echo = T, eval = F}
## Line 2015 ## chunk: census_statistical_area_spatial_intersection

#do the spatial join, create poverty and non whites rates by district. Create a dummy for rates >= stat_area_quantile percentile
# create intersection of tract10 and statareas
lr_tract_statAreas.intersect <- st_intersection(tract10, lr_tract_statAreas)


# get % tract in statares and mulitply by pop totals from each tract
# result is the total tract pops distributed to the statarea by % of tract in statare
lr_tract_statAreas.spJoin <- lr_tract_statAreas.intersect %>% 
  mutate(intersect_area = st_area(lr_tract_statAreas.intersect)) %>% 
  # get % of tract and multiply totals by percent area of tract in statarea
  group_by(tract_id) %>% 
  mutate(intersect_pcnt_of_tract = as.numeric(intersect_area) / as.numeric(tract_area),
         intersect_TotalPop = round(TotalPop * intersect_pcnt_of_tract, 1),
         intersect_NumberWhites = round(NumberWhites * intersect_pcnt_of_tract, 1),
         intersect_TotalPoverty = round(TotalPoverty * intersect_pcnt_of_tract, 1)) %>%
  ungroup() %>% 
  # sum the fraction of pop totals up to statarea
  group_by(stat_area_id) %>%
  summarise(statarea_TotalPop = sum(intersect_TotalPop),
            statarea_NumberWhites = sum(intersect_NumberWhites),
            statarea_TotalPoverty = sum(intersect_TotalPoverty)) %>% 
  # make quantites of interest
  mutate(percentNonWhite = ifelse(statarea_TotalPop > 0, 
                                  ((statarea_TotalPop - statarea_NumberWhites) / statarea_TotalPop),0),
         percentPoverty = ifelse(statarea_TotalPop > 0, 
                                 statarea_TotalPoverty / statarea_TotalPop, 0))

# classify by quantile and make dummy variable
lr_tract_statAreas.spJoin <- lr_tract_statAreas.spJoin %>% 
  mutate(poverty.percentile = ifelse(percentPoverty >=
                                       quantile(lr_tract_statAreas.spJoin$percentPoverty, 
                                                p = stat_area_quantile, na.rm=T),"1",0),
         nonWhite.percentile = ifelse(percentNonWhite >=
                                        quantile(lr_tract_statAreas.spJoin$percentNonWhite, 
                                                 p = stat_area_quantile, na.rm=T),1,0))
```

```{r STAT_AREA_CATEGORY_plot}

## Richmond_PAP_file: line 2051

STAT_AREA_CATEGORY_plot <- lr_tract_statAreas.spJoin %>%
  dplyr::select(poverty.percentile,nonWhite.percentile) %>%
  gather(var,val,-geometry) %>%
  ggplot() +
  geom_sf(aes(fill=factor(val))) +
  facet_wrap(~var) +
  theme_bw()
```


